[{"path":"https://louis-heraut.github.io/CARD/CODE_OF_CONDUCT.html","id":null,"dir":"","previous_headings":"","what":"Contributor Code of Conduct","title":"Contributor Code of Conduct","text":"contributors maintainers project, pledge respect people contribute reporting issues, posting feature requests, updating documentation, submitting pull requests patches, activities. committed making participation project harassment-free experience everyone, regardless level experience, gender, gender identity expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, religion. Examples unacceptable behavior participants include use sexual language imagery, derogatory comments personal attacks, trolling, public private harassment, insults, unprofessional conduct. Project maintainers right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct. Project maintainers follow Code Conduct may removed project team. Instances abusive, harassing, otherwise unacceptable behavior may reported opening issue contacting one project maintainers. Code Conduct adapted Contributor Covenant (https://www.contributor-covenant.org), version 1.0.0, available https://contributor-covenant.org/version/1/0/0/.","code":""},{"path":"https://louis-heraut.github.io/CARD/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing","title":"Contributing","text":"Thank interest contributing CARD ! Whether ‚Äôre fixing bugs, improving documentation, developing new features, appreciate involvement.","code":""},{"path":"https://louis-heraut.github.io/CARD/CONTRIBUTING.html","id":"id_-getting-started","dir":"","previous_headings":"","what":"üöÄ Getting Started","title":"Contributing","text":"‚Äôre unsure begin: - Check open issues. - Feel free open new issue ask questions suggest ideas.","code":""},{"path":"https://louis-heraut.github.io/CARD/CONTRIBUTING.html","id":"want-to-work-on-something","dir":"","previous_headings":"üöÄ Getting Started","what":"Want to Work on Something?","title":"Contributing","text":"plan tackle issue develop something new : - Open comment issue let us know ‚Äôre working . helps avoid duplication promotes collaboration !","code":""},{"path":"https://louis-heraut.github.io/CARD/CONTRIBUTING.html","id":"id_-how-to-contribute","dir":"","previous_headings":"","what":"üîß How to Contribute","title":"Contributing","text":"‚Äôs step--step guide contributing :","code":""},{"path":"https://louis-heraut.github.io/CARD/CONTRIBUTING.html","id":"id_1-fork-the-repository","dir":"","previous_headings":"üîß How to Contribute","what":"1. Fork the Repository","title":"Contributing","text":"Click Fork button top right CARD GitHub page create copy repo GitHub account.","code":""},{"path":"https://louis-heraut.github.io/CARD/CONTRIBUTING.html","id":"id_2-clone-your-fork","dir":"","previous_headings":"üîß How to Contribute","what":"2. Clone Your Fork","title":"Contributing","text":"Clone fork local machine:","code":"git clone git@github.com:your-username/CARD.git cd CARD"},{"path":"https://louis-heraut.github.io/CARD/CONTRIBUTING.html","id":"id_3-create-a-new-branch","dir":"","previous_headings":"üîß How to Contribute","what":"3. Create a New Branch","title":"Contributing","text":"‚Äôs best work dedicated branch feature fix :","code":"git checkout -b your-feature-name"},{"path":"https://louis-heraut.github.io/CARD/CONTRIBUTING.html","id":"id_4-make-your-changes","dir":"","previous_headings":"üîß How to Contribute","what":"4. Make Your Changes","title":"Contributing","text":"Edit code, documentation, tests. sure changes : - Follow project‚Äôs code style - Don‚Äôt break existing functionality - Include comments documentation needed","code":""},{"path":"https://louis-heraut.github.io/CARD/CONTRIBUTING.html","id":"id_5-commit-and-push","dir":"","previous_headings":"üîß How to Contribute","what":"5. Commit and Push","title":"Contributing","text":"testing changes locally :","code":"git add path/to/your-new-file.txt git commit -m \"Clear description of what you did\" git push origin your-feature-name"},{"path":"https://louis-heraut.github.io/CARD/CONTRIBUTING.html","id":"id_6-open-a-pull-request","dir":"","previous_headings":"üîß How to Contribute","what":"6. Open a Pull Request","title":"Contributing","text":"Go fork GitHub click ‚ÄúCompare & Pull Request.‚Äù description changed Link issue ‚Äôre addressing (applicable) Submit PR wait review","code":""},{"path":"https://louis-heraut.github.io/CARD/CONTRIBUTING.html","id":"id_7-address-feedback","dir":"","previous_headings":"üîß How to Contribute","what":"7. Address Feedback","title":"Contributing","text":"PR may receive comments. Please respond, make updates, re-push branch.","code":""},{"path":"https://louis-heraut.github.io/CARD/CONTRIBUTING.html","id":"id_-keeping-your-fork-up-to-date","dir":"","previous_headings":"","what":"üîÑ Keeping Your Fork Up to Date","title":"Contributing","text":"sync fork main repo:","code":""},{"path":"https://louis-heraut.github.io/CARD/CONTRIBUTING.html","id":"option-1-using-githubs-web-interface","dir":"","previous_headings":"üîÑ Keeping Your Fork Up to Date","what":"Option 1: Using GitHub‚Äôs Web Interface","title":"Contributing","text":"Navigate fork Click ‚ÄúSync fork‚Äù (top bar)","code":""},{"path":"https://louis-heraut.github.io/CARD/CONTRIBUTING.html","id":"option-2-using-git-advanced","dir":"","previous_headings":"üîÑ Keeping Your Fork Up to Date","what":"Option 2: Using Git (advanced)","title":"Contributing","text":"","code":"git remote add upstream https://github.com/louis-heraut/CARD.git git fetch upstream git merge upstream/main git push origin main"},{"path":"https://louis-heraut.github.io/CARD/CONTRIBUTING.html","id":"id_-work-collaboration","dir":"","previous_headings":"","what":"ü§ù Work Collaboration","title":"Contributing","text":"‚Äôre connected work ‚Äôd like collaborate deeply : - Reach via email discuss becoming project collaborator.","code":""},{"path":"https://louis-heraut.github.io/CARD/CONTRIBUTING.html","id":"id_-notes","dir":"","previous_headings":"","what":"üìå Notes","title":"Contributing","text":"changes must reviewed merging. use CODEOWNERS manage pull request approvals. Protected branches may require reviews checks pass merging. Thank contributing CARD ! üß™‚ú®","code":""},{"path":"https://louis-heraut.github.io/CARD/articles/V01-climatic_indicators.html","id":"presentation-of-the-dataset","dir":"Articles","previous_headings":"","what":"Presentation of the dataset","title":"Calculation of climatic indicators","text":"package airGRdatasets provides time series gauging stations located Metropolitan French territory. river basins present package : select randomly 3 stations vignette. concat format data three stations:","code":"# Get all data sets in the package station_ids <- ls(\"package:airGRdatasets\")  # Create a table with meta data of each gauging station station_metadata <- dplyr::bind_rows(   lapply(station_ids,   function(id){     data <- base::get(id)     data.frame(CodeH3 = data$Meta$Code$H3,                Name = data$Meta$Name,                Latitude = data$Meta$Coor$Y,                Longitude = data$Meta$Coor$X,                start = first(data$TS$Date),                end = last(data$TS$Date))   }) ) knitr::kable(station_metadata) sel_ids <- sample(station_ids, size = 3) sel_ids #> [1] \"K265401001\" \"K134181001\" \"E645651001\" df_ts <- dplyr::bind_rows(   lapply(sel_ids,   function(id){     df <- base::get(id)$TS     df$id <- id     return(df)   }) ) df_ts$Date <- as.Date(df_ts$Date) # Convert to date format str(df_ts) #> 'data.frame':    21915 obs. of  7 variables: #>  $ Date: Date, format: \"1999-01-01\" \"1999-01-02\" ... #>  $ Ptot: num  0.2 18.9 22.5 0.5 0 0 1.8 16.6 3.4 11.8 ... #>  $ Temp: num  3.8 3.1 4.2 6.1 8.5 8.3 6.1 3 -0.6 -4 ... #>  $ Evap: num  0.4 0.3 0.4 0.5 0.6 0.6 0.5 0.3 0.2 0 ... #>  $ Qls : int  3120 3150 5380 6440 5330 4990 4640 5190 5460 4810 ... #>  $ Qmmd: num  1.25 1.26 2.15 2.57 2.13 ... #>  $ id  : chr  \"K265401001\" \"K265401001\" \"K265401001\" \"K265401001\" ..."},{"path":"https://louis-heraut.github.io/CARD/articles/V01-climatic_indicators.html","id":"statistical-indicators-for-temperatures","dir":"Articles","previous_headings":"","what":"Statistical indicators for temperatures","title":"Calculation of climatic indicators","text":"list available indicators temperature data. use function CARD_list_all() get complete list available indicators. can filter criteria temperatures: , format data function CARD_extraction(). run extraction indicators!","code":"metaEX_all = CARD_list_all() str(metaEX_all) #> tibble [563 √ó 23] (S3: tbl_df/tbl/data.frame) #>  $ CARD_name                : chr [1:563] \"ETPA\" \"BFI-Wal\" \"BFM\" \"delta{centerBF}_H1\" ... #>  $ variable_en              : chr [1:563] \"ETPA\" \"BFI-Wal\" \"BFM\" \"delta{centerBF}_H1\" ... #>  $ unit_en                  : chr [1:563] \"mm\" \"without unit\" \"without unit\" \"day\" ... #>  $ name_en                  : chr [1:563] \"Cumulative annual evapotranspiration\" \"Baseflow index\" \"Baseflow magnitude\" \"Average change of the center of low flows between the near horizon and historical period\" ... #>  $ description_en           : chr [1:563] \"\" \"Ratio between mean inter-annual base flow and mean inter-annual flow\" \"\" \"Date when 50 % of the annual cumulative baseflow is reached\" ... #>  $ method_en                : chr [1:563] \"\" \"1. no temporal aggregation - extraction of the base flow (Wallingford)\\n2. no temporal aggregation - calculatio\"| __truncated__ \"1. no temporal aggregation - extraction of the base flow (Wallingford)\\n2. aggregation by day of the year - ave\"| __truncated__ \"1. annual aggregation [09-01, 08-31] - date when the baseflow (Wallingford) sum corresponds to 50 % of the tota\"| __truncated__ ... #>  $ sampling_period_en       : chr [1:563] \"09-01, 08-31\" NA NA \"09-01, 08-31\" ... #>  $ topic_en                 : chr [1:563] \"Evapotranspiration, Average, Intensity\" \"Flow, Base Flow, Intensity\" \"Flow, Base Flow, Intensity\" \"Flow, Baseflow, Seasonality\" ... #>  $ variable_fr              : chr [1:563] \"ETPA\" \"BFI-Wal\" \"BFM\" \"delta{centreQB}_H1\" ... #>  $ unit_fr                  : chr [1:563] \"mm\" \"sans unit√©\" \"sans unit√©\" \"jour\" ... #>  $ name_fr                  : chr [1:563] \"Cumul des √©vapotranspirations annuelles\" \"Indice de d√©bit de base\" \"Magnitude du d√©bit de base\" \"Changement moyen du centre des √©coulements lents entre l'horizon proche et la p√©riode historique\" ... #>  $ description_fr           : chr [1:563] \"\" \"Rapport entre d√©bit de base moyen inter-annuel et d√©bit moyen inter-annuel\" \"\" \"Date √† laquelle 50 % du cumul annuel du d√©bit de base sont atteints\" ... #>  $ method_fr                : chr [1:563] \"\" \"1. aucune agr√©gation temporelle - extraction du d√©bit de base (Wallingford)\\n2. aucune agr√©gation temporelle - calcul du BFI\" \"1. aucune agr√©gation temporelle - extraction du d√©bit de base (Wallingford)\\n2. agr√©gation par jour de l‚Äôann√©e \"| __truncated__ \"1. agr√©gation annuelle [01-09, 31-08] - date √† laquelle la somme du d√©bit de base (Wallingford) correspond √† 50\"| __truncated__ ... #>  $ sampling_period_fr       : chr [1:563] \"01-09, 31-08\" NA NA \"01-09, 31-08\" ... #>  $ topic_fr                 : chr [1:563] \"√âvapotranspiration, Moyenne, Intensit√©\" \"D√©bit, D√©bit de Base, Intensit√©\" \"D√©bit, D√©bit de Base, Intensit√©\" \"D√©bit, D√©bit de Base, Saisonnalit√©\" ... #>  $ is_experimental          : logi [1:563] FALSE FALSE FALSE FALSE FALSE FALSE ... #>  $ input_vars               : chr [1:563] \"ETP\" \"Q\" \"Q\" \"Q\" ... #>  $ source                   : chr [1:563] NA \"TALLAKSEN, L. et H. VAN LANEN, √©d. (2004). Hydrological drought. Processes and estimation methods for streamflo\"| __truncated__ \"TALLAKSEN, L. et H. VAN LANEN, √©d. (2004). Hydrological drought. Processes and estimation methods for streamflo\"| __truncated__ \"TALLAKSEN, L. et H. VAN LANEN, √©d. (2004). Hydrological drought. Processes and estimation methods for streamflo\"| __truncated__ ... #>  $ preferred_sampling_period: chr [1:563] NA NA NA \"09-01\" ... #>  $ is_date                  : logi [1:563] FALSE FALSE FALSE TRUE TRUE TRUE ... #>  $ to_normalise             : logi [1:563] FALSE FALSE FALSE FALSE FALSE FALSE ... #>  $ palette                  : chr [1:563] \"#452C1A #7F4A23 #B3762A #D4B86A #EFE0B0 #BCE6DB #7ACEB9 #449C93 #2A6863 #193830\" NA NA \"#60265e #893687 #c05fbe #dba3da #edd1ec #f6ddd3 #edbaa7 #e08765 #CD5629 #8f3c1d\" ... #>  $ script_path              : chr [1:563] \"Evapotranspiration/ETPA.R\" \"Flow/Baseflow/criteria/BFI-Wal.R\" \"Flow/Baseflow/criteria/BFM.R\" \"Flow/Baseflow/criteria/delta{centerBF}_H.R\" ... metaEX_temp <- metaEX_all %>%   filter(grepl(\"Temperature\", topic_en),          !grepl(\"Sensitivity_to_Climate_Variability\", script_path)) knitr::kable(metaEX_temp %>% select(\"variable_en\", \"name_en\")) df_temp <- df_ts %>%   select(\"Date\", \"id\", \"Temp\") %>%   rename(T = \"Temp\") str(df_temp) #> 'data.frame':    21915 obs. of  3 variables: #>  $ Date: Date, format: \"1999-01-01\" \"1999-01-02\" ... #>  $ id  : chr  \"K265401001\" \"K265401001\" \"K265401001\" \"K265401001\" ... #>  $ T   : num  3.8 3.1 4.2 6.1 8.5 8.3 6.1 3 -0.6 -4 ... res_temp <- CARD_extraction(   df_temp,   CARD_name = metaEX_temp$variable_en ) str(res_temp) #> List of 2 #>  $ metaEX: tibble [2 √ó 20] (S3: tbl_df/tbl/data.frame) #>   ..$ variable_en       : chr [1:2] \"meanTA\" \"TA\" #>   ..$ unit_en           : chr [1:2] \"¬∞C\" \"¬∞C\" #>   ..$ name_en           : chr [1:2] \"Average of annual average temperatures\" \"Annual mean temperature\" #>   ..$ description_en    : chr [1:2] \"\" \"\" #>   ..$ method_en         : chr [1:2] \"1. annual aggregation [09-01, 08-31] - mean\\n2. no temporal aggregation - average\" \"\" #>   ..$ sampling_period_en: chr [1:2] \"09-01, 08-31\" \"09-01, 08-31\" #>   ..$ topic_en          : chr [1:2] \"Temperature, Average, Intensity\" \"Temperature, Average, Intensity\" #>   ..$ variable_fr       : chr [1:2] \"moyTA\" \"TA\" #>   ..$ unit_fr           : chr [1:2] \"¬∞C\" \"¬∞C\" #>   ..$ name_fr           : chr [1:2] \"Moyenne des temp√©ratures moyennes annuelles\" \"Temp√©rature moyenne annuelle\" #>   ..$ description_fr    : chr [1:2] \"\" \"\" #>   ..$ method_fr         : chr [1:2] \"1. agr√©gation annuelle [01-09, 31-08] - moyenne\\n2. aucune agr√©gation temporelle - moyenne\" \"\" #>   ..$ sampling_period_fr: chr [1:2] \"01-09, 31-08\" \"01-09, 31-08\" #>   ..$ topic_fr          : chr [1:2] \"Temp√©rature, Moyenne, Intensit√©\" \"Temp√©rature, Moyenne, Intensit√©\" #>   ..$ is_experimental   : logi [1:2] FALSE FALSE #>   ..$ input_vars        : chr [1:2] \"Q\" \"T\" #>   ..$ is_date           : logi [1:2] FALSE FALSE #>   ..$ to_normalise      : logi [1:2] FALSE FALSE #>   ..$ palette           : chr [1:2] \"#053061 #2166AC #4393C3 #92C5DE #D1E5F0 #FDDBC7 #F4A582 #D6604D #B2182B #67001F\" \"#053061 #2166AC #4393C3 #92C5DE #D1E5F0 #FDDBC7 #F4A582 #D6604D #B2182B #67001F\" #>   ..$ script_path       : chr [1:2] \"Temperature/meanTA.R\" \"Temperature/TA.R\" #>  $ dataEX:List of 2 #>   ..$ meanTA: tibble [3 √ó 2] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id    : chr [1:3] \"E645651001\" \"K134181001\" \"K265401001\" #>   .. ..$ meanTA: num [1:3] 10.51 10.28 7.83 #>   ..$ TA    : tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id  : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date: Date[1:63], format: \"1998-09-01\" \"1999-09-01\" ... #>   .. ..$ TA  : num [1:63] NA 10.5 10.7 10.6 10.9 ..."},{"path":"https://louis-heraut.github.io/CARD/articles/V01-climatic_indicators.html","id":"statistical-indicators-for-potential-evapotranspiration","dir":"Articles","previous_headings":"","what":"Statistical indicators for potential evapotranspiration","title":"Calculation of climatic indicators","text":"select criteria evaporation except one evolving flow. , format data run function CARD_extraction().","code":"metaEX_evap <- metaEX_all %>%   filter(grepl(\"Evapotranspiration\", topic_en),          !grepl(\"Flow\", topic_en)) knitr::kable(metaEX_evap %>% select(\"variable_en\", \"name_en\")) df_evap <- df_ts %>%   select(\"Date\", \"id\", \"Evap\") %>%   rename(ETP = \"Evap\") # R is the precipitation variable in the dataframe str(df_evap) #> 'data.frame':    21915 obs. of  3 variables: #>  $ Date: Date, format: \"1999-01-01\" \"1999-01-02\" ... #>  $ id  : chr  \"K265401001\" \"K265401001\" \"K265401001\" \"K265401001\" ... #>  $ ETP : num  0.4 0.3 0.4 0.5 0.6 0.6 0.5 0.3 0.2 0 ... res_evap <- CARD_extraction(   df_evap,   CARD_name = metaEX_evap$variable_en ) str(res_evap) #> List of 2 #>  $ metaEX: tibble [1 √ó 20] (S3: tbl_df/tbl/data.frame) #>   ..$ variable_en       : chr \"ETPA\" #>   ..$ unit_en           : chr \"mm\" #>   ..$ name_en           : chr \"Cumulative annual evapotranspiration\" #>   ..$ description_en    : chr \"\" #>   ..$ method_en         : chr \"\" #>   ..$ sampling_period_en: chr \"09-01, 08-31\" #>   ..$ topic_en          : chr \"Evapotranspiration, Average, Intensity\" #>   ..$ variable_fr       : chr \"ETPA\" #>   ..$ unit_fr           : chr \"mm\" #>   ..$ name_fr           : chr \"Cumul des √©vapotranspirations annuelles\" #>   ..$ description_fr    : chr \"\" #>   ..$ method_fr         : chr \"\" #>   ..$ sampling_period_fr: chr \"01-09, 31-08\" #>   ..$ topic_fr          : chr \"√âvapotranspiration, Moyenne, Intensit√©\" #>   ..$ is_experimental   : logi FALSE #>   ..$ input_vars        : chr \"ETP\" #>   ..$ is_date           : logi FALSE #>   ..$ to_normalise      : logi FALSE #>   ..$ palette           : chr \"#452C1A #7F4A23 #B3762A #D4B86A #EFE0B0 #BCE6DB #7ACEB9 #449C93 #2A6863 #193830\" #>   ..$ script_path       : chr \"Evapotranspiration/ETPA.R\" #>  $ dataEX:List of 1 #>   ..$ ETPA: tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id  : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date: Date[1:63], format: \"1998-09-01\" \"1999-09-01\" ... #>   .. ..$ ETPA: num [1:63] NA 651 655 650 683 ..."},{"path":"https://louis-heraut.github.io/CARD/articles/V01-climatic_indicators.html","id":"statistical-indicators-for-precipitations","dir":"Articles","previous_headings":"","what":"Statistical indicators for precipitations","title":"Calculation of climatic indicators","text":"select criteria precipitations except: criteria using flow, criteria related parametrization, sensitivity climate variability, ratio criteria related liquid solid precipitations , format data run function CARD_extraction().","code":"metaEX_prec <- metaEX_all %>%   filter(grepl(\"Precipitation\", topic_en),          !grepl(\"Flow|Parameterization|Sensitivity to Climate Variability|Ratio\", topic_en),          !grepl(\"liquid|solid|Annual precipitation\", name_en)) knitr::kable(metaEX_prec %>% select(\"variable_en\", \"name_en\")) df_prec <- df_ts %>%   select(\"Date\", \"id\", \"Ptot\") %>%   rename(R = \"Ptot\") # R is the precipitation variable in the dataframe str(df_prec) #> 'data.frame':    21915 obs. of  3 variables: #>  $ Date: Date, format: \"1999-01-01\" \"1999-01-02\" ... #>  $ id  : chr  \"K265401001\" \"K265401001\" \"K265401001\" \"K265401001\" ... #>  $ R   : num  0.2 18.9 22.5 0.5 0 0 1.8 16.6 3.4 11.8 ... res_prec <- CARD_extraction(   df_prec,   CARD_name = metaEX_prec$variable_en ) str(res_prec) #> List of 2 #>  $ metaEX: tibble [7 √ó 20] (S3: tbl_df/tbl/data.frame) #>   ..$ variable_en       : chr [1:7] \"dtCDDA\" \"dtCWDA\" \"dtRA01mm\" \"dtRA20mm\" ... #>   ..$ unit_en           : chr [1:7] \"day\" \"day\" \"day\" \"day\" ... #>   ..$ name_en           : chr [1:7] \"Maximum number of consecutive dry days in the year\" \"Maximum number of consecutive rainy days in the year\" \"Number of rainy days in the year\" \"Number of heavy rain days in the year\" ... #>   ..$ description_en    : chr [1:7] \"Maximum number of consecutive days in the year with less than 1 mm of precipitation\" \"Maximum number of consecutive days in the year with at least 1 mm of precipitation\" \"Number of days with at least 1 mm of precipitation\" \"Number of days with at least 20 mm of precipitation\" ... #>   ..$ method_en         : chr [1:7] \"\" \"\" \"\" \"\" ... #>   ..$ sampling_period_en: chr [1:7] \"09-01, 08-31\" \"09-01, 08-31\" \"09-01, 08-31\" \"09-01, 08-31\" ... #>   ..$ topic_en          : chr [1:7] \"Precipitations, Dry Period, Duration\" \"Precipitations, Low, Duration\" \"Precipitations, Low, Duration\" \"Precipitations, Heavy, Duration\" ... #>   ..$ variable_fr       : chr [1:7] \"dtCDDA\" \"dtCWDA\" \"dtRA01mm\" \"dtRA20mm\" ... #>   ..$ unit_fr           : chr [1:7] \"jour\" \"jour\" \"jour\" \"jour\" ... #>   ..$ name_fr           : chr [1:7] \"Nombre maximal de jours secs cons√©cutifs dans l'ann√©e\" \"Nombre maximal de jours pluvieux cons√©cutifs dans l'ann√©e\" \"Nombre de jours pluvieux dans l'ann√©e\" \"Nombre de jours de forte pluie dans l'ann√©e\" ... #>   ..$ description_fr    : chr [1:7] \"Nombre maximal de jours cons√©cutifs dans l'ann√©e avec moins de 1 mm de pr√©cipitation\" \"Nombre maximal de jours cons√©cutifs dans l'ann√©e avec au moins 1 mm de pr√©cipitation\" \"Nombre de jours avec au moins 1 mm de pr√©cipitations\" \"Nombre de jours avec au moins 20 mm de pr√©cipitations\" ... #>   ..$ method_fr         : chr [1:7] \"\" \"\" \"\" \"\" ... #>   ..$ sampling_period_fr: chr [1:7] \"01-09, 31-08\" \"01-09, 31-08\" \"01-09, 31-08\" \"01-09, 31-08\" ... #>   ..$ topic_fr          : chr [1:7] \"Pr√©cipitations, P√©riode s√®che, Dur√©e\" \"Pr√©cipitations, Faibles, Dur√©e\" \"Pr√©cipitations, Faible, Dur√©e\" \"Pr√©cipitations, Forte, Dur√©e\" ... #>   ..$ is_experimental   : logi [1:7] FALSE FALSE FALSE FALSE FALSE FALSE ... #>   ..$ input_vars        : chr [1:7] \"R\" \"R\" \"R\" \"R\" ... #>   ..$ is_date           : logi [1:7] FALSE FALSE FALSE FALSE FALSE FALSE ... #>   ..$ to_normalise      : logi [1:7] FALSE FALSE FALSE FALSE FALSE FALSE ... #>   ..$ palette           : chr [1:7] \"#003C30 #01665E #35978F #80CDC1 #C7EAE5 #F6E8C3 #DFC27D #BF812D #8C510A #543005\" \"#452C1A #7F4A23 #B3762A #D4B86A #EFE0B0 #BCE6DB #7ACEB9 #449C93 #2A6863 #193830\" \"#452C1A #7F4A23 #B3762A #D4B86A #EFE0B0 #BCE6DB #7ACEB9 #449C93 #2A6863 #193830\" \"#452C1A #7F4A23 #B3762A #D4B86A #EFE0B0 #BCE6DB #7ACEB9 #449C93 #2A6863 #193830\" ... #>   ..$ script_path       : chr [1:7] \"Precipitations/dtCDDA.R\" \"Precipitations/dtCWDA.R\" \"Precipitations/dtRA01mm.R\" \"Precipitations/dtRA20mm.R\" ... #>  $ dataEX:List of 7 #>   ..$ dtCDDA  : tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id    : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date  : Date[1:63], format: \"1998-09-01\" \"1999-09-01\" ... #>   .. ..$ dtCDDA: int [1:63] NA 12 17 27 18 19 17 17 27 19 ... #>   ..$ dtCWDA  : tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id    : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date  : Date[1:63], format: \"1998-09-01\" \"1999-09-01\" ... #>   .. ..$ dtCWDA: int [1:63] NA 16 13 11 11 9 6 17 10 9 ... #>   ..$ dtRA01mm: tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id      : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date    : Date[1:63], format: \"1998-09-01\" \"1999-09-01\" ... #>   .. ..$ dtRA01mm: int [1:63] NA 168 181 162 121 132 135 149 161 142 ... #>   ..$ dtRA20mm: tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id      : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date    : Date[1:63], format: \"1998-09-01\" \"1999-09-01\" ... #>   .. ..$ dtRA20mm: int [1:63] NA 4 5 3 4 NA 2 3 1 7 ... #>   ..$ dtRA50mm: tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id      : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date    : Date[1:63], format: \"1998-09-01\" \"1999-09-01\" ... #>   .. ..$ dtRA50mm: int [1:63] NA NA NA NA NA NA NA NA NA NA ... #>   ..$ RCXA1   : tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id   : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date : Date[1:63], format: \"1998-04-01\" \"1999-04-01\" ... #>   .. ..$ RCXA1: num [1:63] NA 28.5 32.5 30.2 25.1 20.5 22.6 49.2 25.1 31.1 ... #>   ..$ RCXA5   : tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id   : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date : Date[1:63], format: \"1998-04-01\" \"1999-04-01\" ... #>   .. ..$ RCXA5: num [1:63] NA 80 70.6 54.1 64.7 49.4 38.4 85.5 60.4 60.5 ..."},{"path":"https://louis-heraut.github.io/CARD/articles/V02-hydrological_indicators.html","id":"dataset","dir":"Articles","previous_headings":"","what":"Dataset","title":"Calculation of hydrological indicators","text":"use flow time series three random gauging stations provided package airGRdatasets (See vignette V01-climatic_indicators details).","code":"# Get all data sets in the package station_ids <- ls(\"package:airGRdatasets\") # Sample 3 stations sel_ids <- sample(station_ids, size = 3) sel_ids #> [1] \"K265401001\" \"K134181001\" \"E645651001\" # \"Tidy format\" the time series df_ts <- dplyr::bind_rows(   lapply(sel_ids,   function(id){     df <- base::get(id)$TS     df$id <- id     return(df)   }) ) df_ts$Date <- as.Date(df_ts$Date) # Convert to date format str(df_ts) #> 'data.frame':    21915 obs. of  7 variables: #>  $ Date: Date, format: \"1999-01-01\" \"1999-01-02\" ... #>  $ Ptot: num  0.2 18.9 22.5 0.5 0 0 1.8 16.6 3.4 11.8 ... #>  $ Temp: num  3.8 3.1 4.2 6.1 8.5 8.3 6.1 3 -0.6 -4 ... #>  $ Evap: num  0.4 0.3 0.4 0.5 0.6 0.6 0.5 0.3 0.2 0 ... #>  $ Qls : int  3120 3150 5380 6440 5330 4990 4640 5190 5460 4810 ... #>  $ Qmmd: num  1.25 1.26 2.15 2.57 2.13 ... #>  $ id  : chr  \"K265401001\" \"K265401001\" \"K265401001\" \"K265401001\" ..."},{"path":"https://louis-heraut.github.io/CARD/articles/V02-hydrological_indicators.html","id":"selection-of-hydrological-indicators","dir":"Articles","previous_headings":"Dataset","what":"Selection of hydrological indicators","title":"Calculation of hydrological indicators","text":"use function CARD_list_all() get complete list available indicators. can filter criteria flows excluding indicators related : performance hydrological model indicators computed future horizon periods sensitivity climate variability indicators invoking currently bugged function GeneralMannKendall_WRAP indicator med{dtRec} currently crashing Finally, format data run function CARD_extraction().","code":"metaEX_all = CARD_list_all() str(metaEX_all) #> tibble [563 √ó 23] (S3: tbl_df/tbl/data.frame) #>  $ CARD_name                : chr [1:563] \"ETPA\" \"BFI-Wal\" \"BFM\" \"delta{centerBF}_H1\" ... #>  $ variable_en              : chr [1:563] \"ETPA\" \"BFI-Wal\" \"BFM\" \"delta{centerBF}_H1\" ... #>  $ unit_en                  : chr [1:563] \"mm\" \"without unit\" \"without unit\" \"day\" ... #>  $ name_en                  : chr [1:563] \"Cumulative annual evapotranspiration\" \"Baseflow index\" \"Baseflow magnitude\" \"Average change of the center of low flows between the near horizon and historical period\" ... #>  $ description_en           : chr [1:563] \"\" \"Ratio between mean inter-annual base flow and mean inter-annual flow\" \"\" \"Date when 50 % of the annual cumulative baseflow is reached\" ... #>  $ method_en                : chr [1:563] \"\" \"1. no temporal aggregation - extraction of the base flow (Wallingford)\\n2. no temporal aggregation - calculatio\"| __truncated__ \"1. no temporal aggregation - extraction of the base flow (Wallingford)\\n2. aggregation by day of the year - ave\"| __truncated__ \"1. annual aggregation [09-01, 08-31] - date when the baseflow (Wallingford) sum corresponds to 50 % of the tota\"| __truncated__ ... #>  $ sampling_period_en       : chr [1:563] \"09-01, 08-31\" NA NA \"09-01, 08-31\" ... #>  $ topic_en                 : chr [1:563] \"Evapotranspiration, Average, Intensity\" \"Flow, Base Flow, Intensity\" \"Flow, Base Flow, Intensity\" \"Flow, Baseflow, Seasonality\" ... #>  $ variable_fr              : chr [1:563] \"ETPA\" \"BFI-Wal\" \"BFM\" \"delta{centreQB}_H1\" ... #>  $ unit_fr                  : chr [1:563] \"mm\" \"sans unit√©\" \"sans unit√©\" \"jour\" ... #>  $ name_fr                  : chr [1:563] \"Cumul des √©vapotranspirations annuelles\" \"Indice de d√©bit de base\" \"Magnitude du d√©bit de base\" \"Changement moyen du centre des √©coulements lents entre l'horizon proche et la p√©riode historique\" ... #>  $ description_fr           : chr [1:563] \"\" \"Rapport entre d√©bit de base moyen inter-annuel et d√©bit moyen inter-annuel\" \"\" \"Date √† laquelle 50 % du cumul annuel du d√©bit de base sont atteints\" ... #>  $ method_fr                : chr [1:563] \"\" \"1. aucune agr√©gation temporelle - extraction du d√©bit de base (Wallingford)\\n2. aucune agr√©gation temporelle - calcul du BFI\" \"1. aucune agr√©gation temporelle - extraction du d√©bit de base (Wallingford)\\n2. agr√©gation par jour de l‚Äôann√©e \"| __truncated__ \"1. agr√©gation annuelle [01-09, 31-08] - date √† laquelle la somme du d√©bit de base (Wallingford) correspond √† 50\"| __truncated__ ... #>  $ sampling_period_fr       : chr [1:563] \"01-09, 31-08\" NA NA \"01-09, 31-08\" ... #>  $ topic_fr                 : chr [1:563] \"√âvapotranspiration, Moyenne, Intensit√©\" \"D√©bit, D√©bit de Base, Intensit√©\" \"D√©bit, D√©bit de Base, Intensit√©\" \"D√©bit, D√©bit de Base, Saisonnalit√©\" ... #>  $ is_experimental          : logi [1:563] FALSE FALSE FALSE FALSE FALSE FALSE ... #>  $ input_vars               : chr [1:563] \"ETP\" \"Q\" \"Q\" \"Q\" ... #>  $ source                   : chr [1:563] NA \"TALLAKSEN, L. et H. VAN LANEN, √©d. (2004). Hydrological drought. Processes and estimation methods for streamflo\"| __truncated__ \"TALLAKSEN, L. et H. VAN LANEN, √©d. (2004). Hydrological drought. Processes and estimation methods for streamflo\"| __truncated__ \"TALLAKSEN, L. et H. VAN LANEN, √©d. (2004). Hydrological drought. Processes and estimation methods for streamflo\"| __truncated__ ... #>  $ preferred_sampling_period: chr [1:563] NA NA NA \"09-01\" ... #>  $ is_date                  : logi [1:563] FALSE FALSE FALSE TRUE TRUE TRUE ... #>  $ to_normalise             : logi [1:563] FALSE FALSE FALSE FALSE FALSE FALSE ... #>  $ palette                  : chr [1:563] \"#452C1A #7F4A23 #B3762A #D4B86A #EFE0B0 #BCE6DB #7ACEB9 #449C93 #2A6863 #193830\" NA NA \"#60265e #893687 #c05fbe #dba3da #edd1ec #f6ddd3 #edbaa7 #e08765 #CD5629 #8f3c1d\" ... #>  $ script_path              : chr [1:563] \"Evapotranspiration/ETPA.R\" \"Flow/Baseflow/criteria/BFI-Wal.R\" \"Flow/Baseflow/criteria/BFM.R\" \"Flow/Baseflow/criteria/delta{centerBF}_H.R\" ... metaEX_flow <- metaEX_all %>%   filter(grepl(\"Flow\", topic_en),          !grepl(\"Performance\", topic_en),          !grepl(\"_H[0-3]*$\" , variable_en),          !grepl(\"Sensitivity_to_Climate_Variability\", script_path),          # 'GeneralMannKendall_WRAP' is not an exported object from 'namespace:EXstat'          !grepl(\"alpha\" , variable_en),          # Error in `dplyr::arrange()`: In argument: `..1 = get(date_col)`          variable_en != \"med{dtRec}\") knitr::kable(metaEX_flow %>% select(\"variable_en\", name_en)) df_flow <- df_ts %>%   select(\"Date\", \"id\", \"Qls\") %>%   rename(Q = \"Qls\") %>%   mutate(Q = Q / 1000) # Convert to m3/s str(df_flow) #> 'data.frame':    21915 obs. of  3 variables: #>  $ Date: Date, format: \"1999-01-01\" \"1999-01-02\" ... #>  $ id  : chr  \"K265401001\" \"K265401001\" \"K265401001\" \"K265401001\" ... #>  $ Q   : num  3.12 3.15 5.38 6.44 5.33 4.99 4.64 5.19 5.46 4.81 ... res_flow <- CARD_extraction(   df_flow,   CARD_name = metaEX_flow$variable_en ) #> Warning: Returning more (or less) than 1 row per `summarise()` group was deprecated in #> dplyr 1.1.0. #> ‚Ñπ Please use `reframe()` instead. #> ‚Ñπ When switching from `summarise()` to `reframe()`, remember that `reframe()` #>   always returns an ungrouped data frame and adjust accordingly. #> ‚Ñπ The deprecated feature was likely used in the EXstat package. #>   Please report the issue to the authors. #> This warning is displayed once every 8 hours. #> Call `lifecycle::last_lifecycle_warnings()` to see where this warning was #> generated. #> Warning in process_extraction(data = data, funct = funct, funct_args = #> funct_args, : 'keep' is coherced to NULL. 'keep' can be non NULL only if #> 'time_step' is not 'month', 'season' or 'yearday'. #> Warning: There were 1098 warnings in `dplyr::summarise()`. #> The first warning was: #> ‚Ñπ In argument: `ValueEX1 = f(\"Q_obs\", na.rm = TRUE)`. #> ‚Ñπ In group 1: `Code = \"E645651001\"` `group = 1`. #> Caused by warning in `mean.default()`: #> ! argument is not numeric or logical: returning NA #> ‚Ñπ Run `dplyr::last_dplyr_warnings()` to see the 1097 remaining warnings. #> 'keep' seems to only select aggragated column. Thus, 'keep' will be coherced to NULL. str(res_flow) #> List of 2 #>  $ metaEX: tibble [72 √ó 22] (S3: tbl_df/tbl/data.frame) #>   ..$ variable_en              : chr [1:72] \"BFI-Wal\" \"BFM\" \"med{centerBF}\" \"med{dtBF}\" ... #>   ..$ unit_en                  : chr [1:72] \"without unit\" \"without unit\" \"yearday\" \"day\" ... #>   ..$ name_en                  : chr [1:72] \"Baseflow index\" \"Baseflow magnitude\" \"Median center of baseflow\" \"Median duration of baseflow\" ... #>   ..$ description_en           : chr [1:72] \"Ratio between mean inter-annual base flow and mean inter-annual flow\" \"\" \"Median of the dates at which 50 % of the annual cumulative baseflow is reached\" \"Median of the durations between the start and end of baseflow\" ... #>   ..$ method_en                : chr [1:72] \"1. no temporal aggregation - extraction of the base flow (Wallingford)\\n2. no temporal aggregation - calculatio\"| __truncated__ \"1. no temporal aggregation - extraction of the base flow (Wallingford)\\n2. aggregation by day of the year - ave\"| __truncated__ \"1. annual aggregation [09-01, 08-31] - date at which the baseflow (Wallingford) sum Qb (Section 8.6.2) correspo\"| __truncated__ \"1. annual aggregation [09-01, 08-31] - number of days between the dates at which the baseflow (Wallingford) sum\"| __truncated__ ... #>   ..$ topic_en                 : chr [1:72] \"Flow, Base Flow, Intensity\" \"Flow, Base Flow, Intensity\" \"Flow, Baseflow, Seasonality\" \"Flow, Baseflow, Duration\" ... #>   ..$ variable_fr              : chr [1:72] \"BFI-Wal\" \"BFM\" \"med{centreQB}\" \"med{dtQB}\" ... #>   ..$ unit_fr                  : chr [1:72] \"sans unit√©\" \"sans unit√©\" \"jour de l'ann√©e\" \"jour\" ... #>   ..$ name_fr                  : chr [1:72] \"Indice de d√©bit de base\" \"Magnitude du d√©bit de base\" \"M√©diane du centre des √©coulements lents\" \"M√©diane de la dur√©e des √©coulements lents\" ... #>   ..$ description_fr           : chr [1:72] \"Rapport entre d√©bit de base moyen inter-annuel et d√©bit moyen inter-annuel\" \"\" \"M√©diane des dates √† laquelle 50 % du cumul annuel du d√©bit de base sont atteints\" \"M√©diane des dur√©es entre le d√©but et la fin des √©coulements lents\" ... #>   ..$ method_fr                : chr [1:72] \"1. aucune agr√©gation temporelle - extraction du d√©bit de base (Wallingford)\\n2. aucune agr√©gation temporelle - calcul du BFI\" \"1. aucune agr√©gation temporelle - extraction du d√©bit de base (Wallingford)\\n2. agr√©gation par jour de l‚Äôann√©e \"| __truncated__ \"1. agr√©gation annuelle [01-09, 31-08] - date √† laquelle la somme du d√©bit de base (Wallingford) Qb (Section 8.6\"| __truncated__ \"1. agr√©gation annuelle [01-09, 31-08] - nombre de jours entre les dates auxquelles la somme du d√©bit de base (W\"| __truncated__ ... #>   ..$ topic_fr                 : chr [1:72] \"D√©bit, D√©bit de Base, Intensit√©\" \"D√©bit, D√©bit de Base, Intensit√©\" \"D√©bit, D√©bit de Base, Saisonnalit√©\" \"D√©bit, D√©bit de Base, Dur√©e\" ... #>   ..$ is_experimental          : logi [1:72] FALSE FALSE FALSE FALSE FALSE FALSE ... #>   ..$ input_vars               : chr [1:72] \"Q\" \"Q\" \"Q\" \"Q\" ... #>   ..$ source                   : chr [1:72] \"TALLAKSEN, L. et H. VAN LANEN, √©d. (2004). Hydrological drought. Processes and estimation methods for streamflo\"| __truncated__ \"TALLAKSEN, L. et H. VAN LANEN, √©d. (2004). Hydrological drought. Processes and estimation methods for streamflo\"| __truncated__ \"TALLAKSEN, L. et H. VAN LANEN, √©d. (2004). Hydrological drought. Processes and estimation methods for streamflo\"| __truncated__ \"TALLAKSEN, L. et H. VAN LANEN, √©d. (2004). Hydrological drought. Processes and estimation methods for streamflo\"| __truncated__ ... #>   ..$ preferred_sampling_period: chr [1:72] NA NA \"09-01\" \"09-01\" ... #>   ..$ is_date                  : logi [1:72] FALSE FALSE TRUE FALSE TRUE TRUE ... #>   ..$ to_normalise             : logi [1:72] FALSE FALSE FALSE TRUE FALSE FALSE ... #>   ..$ script_path              : chr [1:72] \"Flow/Baseflow/criteria/BFI-Wal.R\" \"Flow/Baseflow/criteria/BFM.R\" \"Flow/Baseflow/criteria/med{centerBF}.R\" \"Flow/Baseflow/criteria/med{dtBF}.R\" ... #>   ..$ sampling_period_en       : chr [1:72] NA NA \"09-01, 08-31\" \"09-01, 08-31\" ... #>   ..$ sampling_period_fr       : chr [1:72] NA NA \"01-09, 31-08\" \"01-09, 31-08\" ... #>   ..$ palette                  : chr [1:72] NA NA NA NA ... #>  $ dataEX:List of 72 #>   ..$ BFI-Wal      : tibble [3 √ó 2] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id     : chr [1:3] \"E645651001\" \"K134181001\" \"K265401001\" #>   .. ..$ BFI-Wal: num [1:3] 0.974 0.511 0.693 #>   ..$ BFM          : tibble [3 √ó 2] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id : chr [1:3] \"E645651001\" \"K134181001\" \"K265401001\" #>   .. ..$ BFM: num [1:3] 0.146 0.937 0.8 #>   ..$ med{centerBF}: tibble [3 √ó 2] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id           : chr [1:3] \"E645651001\" \"K134181001\" \"K265401001\" #>   .. ..$ med{centerBF}: num [1:3] 68 40 62 #>   ..$ med{dtBF}    : tibble [3 √ó 2] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id       : chr [1:3] \"E645651001\" \"K134181001\" \"K265401001\" #>   .. ..$ med{dtBF}: num [1:3] 284 164 206 #>   ..$ med{endBF}   : tibble [3 √ó 2] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id        : chr [1:3] \"E645651001\" \"K134181001\" \"K265401001\" #>   .. ..$ med{endBF}: num [1:3] 201 133 164 #>   ..$ med{startBF} : tibble [3 √ó 2] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id          : chr [1:3] \"E645651001\" \"K134181001\" \"K265401001\" #>   .. ..$ med{startBF}: num [1:3] 282 325 320 #>   ..$ med{vBF}     : tibble [3 √ó 2] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id      : chr [1:3] \"E645651001\" \"K134181001\" \"K265401001\" #>   .. ..$ med{vBF}: num [1:3] 62.3 388.5 88.7 #>   ..$ BF-LH        : tibble [21,915 √ó 4] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id   : chr [1:21915] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date : Date[1:21915], format: \"1999-01-01\" \"1999-01-02\" ... #>   .. ..$ Q    : num [1:21915] 1.75 1.79 1.84 1.89 1.92 1.86 1.99 1.98 1.93 1.88 ... #>   .. ..$ BF-LH: num [1:21915] 1.75 1.75 1.75 1.75 1.75 ... #>   ..$ centerBF     : tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id      : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date    : Date[1:63], format: \"1998-09-01\" \"1999-09-01\" ... #>   .. ..$ centerBF: num [1:63] NA NA 94 75 62 NA NA NA 75 NA ... #>   ..$ dtBF         : tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id  : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date: Date[1:63], format: \"1998-09-01\" \"1999-09-01\" ... #>   .. ..$ dtBF: num [1:63] NA NA 269 284 279 NA NA NA 290 NA ... #>   ..$ endBF        : tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id   : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date : Date[1:63], format: \"1998-09-01\" \"1999-09-01\" ... #>   .. ..$ endBF: num [1:63] NA NA 203 197 197 NA NA NA 206 NA ... #>   ..$ startBF      : tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id     : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date   : Date[1:63], format: \"1998-09-01\" \"1999-09-01\" ... #>   .. ..$ startBF: num [1:63] NA NA 301 279 284 NA NA NA 282 NA ... #>   ..$ vBF          : tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id  : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date: Date[1:63], format: \"1998-09-01\" \"1999-09-01\" ... #>   .. ..$ vBF : num [1:63] NA 71.5 108.7 91.9 77.3 ... #>   ..$ med{dtFlood} : tibble [3 √ó 2] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id          : chr [1:3] \"E645651001\" \"K134181001\" \"K265401001\" #>   .. ..$ med{dtFlood}: num [1:3] 2 3 4 #>   ..$ med{tQJXA}   : tibble [3 √ó 2] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id        : chr [1:3] \"E645651001\" \"K134181001\" \"K265401001\" #>   .. ..$ med{tQJXA}: num [1:3] 44.3 36.4 41.3 #>   ..$ Q10          : tibble [3 √ó 2] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id : chr [1:3] \"E645651001\" \"K134181001\" \"K265401001\" #>   .. ..$ Q10: num [1:3] 2.74 66.96 8.47 #>   ..$ QJXA-10      : tibble [3 √ó 2] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id     : chr [1:3] \"E645651001\" \"K134181001\" \"K265401001\" #>   .. ..$ QJXA-10: num [1:3] 5.54 344.96 46.72 #>   ..$ dtFlood      : tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id     : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date   : Date[1:63], format: \"1998-10-01\" \"1999-10-01\" ... #>   .. ..$ dtFlood: int [1:63] NA 2 2 1 1 NA NA NA NA 2 ... #>   ..$ fQ01A        : tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id   : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date : Date[1:63], format: \"1998-10-01\" \"1999-10-01\" ... #>   .. ..$ fQ01A: num [1:63] NA 0.00273 0.17808 0.00548 0 ... #>   ..$ fQ05A        : tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id   : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date : Date[1:63], format: \"1998-10-01\" \"1999-10-01\" ... #>   .. ..$ fQ05A: num [1:63] NA 0.00546 0.58082 0.32055 0.0137 ... #>   ..$ fQ10A        : tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id   : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date : Date[1:63], format: \"1998-10-01\" \"1999-10-01\" ... #>   .. ..$ fQ10A: num [1:63] NA 0.148 0.822 0.466 0.359 ... #>   ..$ Q01A         : tibble [60 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id  : chr [1:60] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date: Date[1:60], format: \"1999-01-01\" \"2000-01-01\" ... #>   .. ..$ Q01A: num [1:60] NA 3.03 5.91 4.15 3.22 ... #>   ..$ Q05A         : tibble [60 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id  : chr [1:60] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date: Date[1:60], format: \"1999-01-01\" \"2000-01-01\" ... #>   .. ..$ Q05A: num [1:60] NA 2.89 5.32 4.02 3.04 ... #>   ..$ Q10A         : tibble [60 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id  : chr [1:60] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date: Date[1:60], format: \"1999-01-01\" \"2000-01-01\" ... #>   .. ..$ Q10A: num [1:60] NA 2.85 5.14 3.87 2.98 ... #>   ..$ QJXA         : tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id  : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date: Date[1:63], format: \"1998-10-01\" \"1999-10-01\" ... #>   .. ..$ QJXA: num [1:63] NA 5.4 6.2 5.25 3.9 NA NA NA NA 3.02 ... #>   ..$ tQJXA        : tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id   : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date : Date[1:63], format: \"1998-10-01\" \"1999-10-01\" ... #>   .. ..$ tQJXA: num [1:63] NA -6 98 78 1 NA NA NA NA 220 ... #>   ..$ tVCX10       : tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id    : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date  : Date[1:63], format: \"1998-10-01\" \"1999-10-01\" ... #>   .. ..$ tVCX10: num [1:63] NA -3 118 107 62 NA NA NA NA NA ... #>   ..$ tVCX3        : tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id   : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date : Date[1:63], format: \"1998-10-01\" \"1999-10-01\" ... #>   .. ..$ tVCX3: num [1:63] NA -5 117 79 2 NA NA NA NA 220 ... #>   ..$ VCX10        : tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id   : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date : Date[1:63], format: \"1998-10-01\" \"1999-10-01\" ... #>   .. ..$ VCX10: num [1:63] NA 3.05 5.55 4.05 3.1 ... #>   ..$ VCX3         : tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id  : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date: Date[1:63], format: \"1998-10-01\" \"1999-10-01\" ... #>   .. ..$ VCX3: num [1:63] NA 4.11 5.82 4.66 3.37 ... #>   ..$ QMNA_summer  : tibble [60 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id         : chr [1:60] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date       : Date[1:60], format: \"1999-05-01\" \"2000-05-01\" ... #>   .. ..$ QMNA_summer: num [1:60] NA 2.17 2.64 2.03 1.69 ... #>   ..$ QNA_summer   : tibble [60 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id        : chr [1:60] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date      : Date[1:60], format: \"1999-05-01\" \"2000-05-01\" ... #>   .. ..$ QNA_summer: num [1:60] NA 2.08 2.46 1.92 1.61 1.1 NA 1.44 NA 1.82 ... #>   ..$ tVCN10_summer: tibble [60 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id           : chr [1:60] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date         : Date[1:60], format: \"1999-05-01\" \"2000-05-01\" ... #>   .. ..$ tVCN10_summer: num [1:60] NA 252 326 299 313 304 NA 308 NA 267 ... #>   ..$ VCN10_summer : tibble [60 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id          : chr [1:60] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date        : Date[1:60], format: \"1999-05-01\" \"2000-05-01\" ... #>   .. ..$ VCN10_summer: num [1:60] NA 2.1 2.52 2.01 1.65 ... #>   ..$ VCN3_summer  : tibble [60 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id         : chr [1:60] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date       : Date[1:60], format: \"1999-05-01\" \"2000-05-01\" ... #>   .. ..$ VCN3_summer: num [1:60] NA 2.09 2.49 1.94 1.62 ... #>   ..$ VCN30_summer : tibble [60 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id          : chr [1:60] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date        : Date[1:60], format: \"1999-05-01\" \"2000-05-01\" ... #>   .. ..$ VCN30_summer: num [1:60] NA 2.15 2.6 2.02 1.66 ... #>   ..$ QMNA_winter  : tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id         : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date       : Date[1:63], format: \"1998-11-01\" \"1999-11-01\" ... #>   .. ..$ QMNA_winter: num [1:63] NA 1.87 2.49 2.46 2.26 ... #>   ..$ QNA_winter   : tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id        : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date      : Date[1:63], format: \"1998-11-01\" \"1999-11-01\" ... #>   .. ..$ QNA_winter: num [1:63] NA 1.72 2.31 2.3 1.94 NA NA NA 1.44 1.51 ... #>   ..$ tVCN10_winter: tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id           : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date         : Date[1:63], format: \"1998-11-01\" \"1999-11-01\" ... #>   .. ..$ tVCN10_winter: num [1:63] NA 336 305 377 304 NA NA NA 308 317 ... #>   ..$ VCN10_winter : tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id          : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date        : Date[1:63], format: \"1998-11-01\" \"1999-11-01\" ... #>   .. ..$ VCN10_winter: num [1:63] NA 1.77 2.34 2.35 2.12 ... #>   ..$ VCN3_winter  : tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id         : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date       : Date[1:63], format: \"1998-11-01\" \"1999-11-01\" ... #>   .. ..$ VCN3_winter: num [1:63] NA 1.73 2.32 2.31 2.06 ... #>   ..$ VCN30_winter : tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id          : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date        : Date[1:63], format: \"1998-11-01\" \"1999-11-01\" ... #>   .. ..$ VCN30_winter: num [1:63] NA 1.84 2.38 2.38 2.19 ... #>   ..$ med{dtLF}    : tibble [3 √ó 2] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id       : chr [1:3] \"E645651001\" \"K134181001\" \"K265401001\" #>   .. ..$ med{dtLF}: num [1:3] 279 71 84 #>   ..$ med{startLF} : tibble [3 √ó 2] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id          : chr [1:3] \"E645651001\" \"K134181001\" \"K265401001\" #>   .. ..$ med{startLF}: num [1:3] 91 201 195 #>   ..$ med{tVCN10}  : tibble [3 √ó 2] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id         : chr [1:3] \"E645651001\" \"K134181001\" \"K265401001\" #>   .. ..$ med{tVCN10}: num [1:3] 304 247 244 #>   ..$ med{vLF}     : tibble [3 √ó 2] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id      : chr [1:3] \"E645651001\" \"K134181001\" \"K265401001\" #>   .. ..$ med{vLF}: num [1:3] 42.34 15.06 9.11 #>   ..$ Q90          : tibble [3 √ó 2] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id : chr [1:3] \"E645651001\" \"K134181001\" \"K265401001\" #>   .. ..$ Q90: num [1:3] 1.42 1.91 1.03 #>   ..$ QMNA-5       : tibble [3 √ó 2] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id    : chr [1:3] \"E645651001\" \"K134181001\" \"K265401001\" #>   .. ..$ QMNA-5: num [1:3] 1.459 1.33 0.939 #>   ..$ VCN10-5      : tibble [3 √ó 2] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id     : chr [1:3] \"E645651001\" \"K134181001\" \"K265401001\" #>   .. ..$ VCN10-5: num [1:3] 1.407 0.893 0.754 #>   ..$ VCN30-2      : tibble [3 √ó 2] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id     : chr [1:3] \"E645651001\" \"K134181001\" \"K265401001\" #>   .. ..$ VCN30-2: num [1:3] 1.69 2 1.06 #>   ..$ Q90A         : tibble [60 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id  : chr [1:60] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date: Date[1:60], format: \"1999-01-01\" \"2000-01-01\" ... #>   .. ..$ Q90A: num [1:60] NA 2.21 2.55 2.09 1.64 ... #>   ..$ Q95A         : tibble [60 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id  : chr [1:60] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date: Date[1:60], format: \"1999-01-01\" \"2000-01-01\" ... #>   .. ..$ Q95A: num [1:60] NA 2.15 2.5 2.02 1.62 ... #>   ..$ Q99A         : tibble [60 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id  : chr [1:60] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date: Date[1:60], format: \"1999-01-01\" \"2000-01-01\" ... #>   .. ..$ Q99A: num [1:60] NA 2.09 2.38 1.96 1.55 ... #>   ..$ QMNA         : tibble [62 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id  : chr [1:62] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date: Date[1:62], format: \"1998-04-01\" \"1999-04-01\" ... #>   .. ..$ QMNA: num [1:62] NA NA 2.17 2.46 2.03 ... #>   ..$ QNA          : tibble [62 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id  : chr [1:62] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date: Date[1:62], format: \"1998-04-01\" \"1999-04-01\" ... #>   .. ..$ QNA : num [1:62] NA NA 2.08 2.3 1.92 NA NA NA 1.44 NA ... #>   ..$ tVCN10       : tibble [62 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id    : chr [1:62] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date  : Date[1:62], format: \"1998-04-01\" \"1999-04-01\" ... #>   .. ..$ tVCN10: num [1:62] NA NA 252 377 299 NA NA NA 308 NA ... #>   ..$ VCN10        : tibble [62 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id   : chr [1:62] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date : Date[1:62], format: \"1998-04-01\" \"1999-04-01\" ... #>   .. ..$ VCN10: num [1:62] NA NA 2.1 2.35 2.01 ... #>   ..$ VCN3         : tibble [62 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id  : chr [1:62] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date: Date[1:62], format: \"1998-04-01\" \"1999-04-01\" ... #>   .. ..$ VCN3: num [1:62] NA NA 2.09 2.31 1.94 ... #>   ..$ VCN30        : tibble [62 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id   : chr [1:62] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date : Date[1:62], format: \"1998-04-01\" \"1999-04-01\" ... #>   .. ..$ VCN30: num [1:62] NA NA 2.15 2.38 2.02 ... #>   ..$ aFDC         : tibble [3 √ó 2] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id  : chr [1:3] \"E645651001\" \"K134181001\" \"K265401001\" #>   .. ..$ aFDC: num [1:3] -0.325 -1.699 -1.109 #>   ..$ meanQA       : tibble [3 √ó 2] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id    : chr [1:3] \"E645651001\" \"K134181001\" \"K265401001\" #>   .. ..$ meanQA: num [1:3] 2.15 25.95 4.23 #>   ..$ Q50          : tibble [3 √ó 2] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id : chr [1:3] \"E645651001\" \"K134181001\" \"K265401001\" #>   .. ..$ Q50: num [1:3] 1.89 12 2.91 #>   ..$ FDC          : tibble [3,000 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id   : chr [1:3000] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ FDC_p: num [1:3000] 0.00135 0.00138 0.0014 0.00143 0.00146 ... #>   .. ..$ FDC_Q: num [1:3000] 5.52 5.52 5.52 5.51 5.51 ... #>   ..$ medQJ        : tibble [1,095 √ó 4] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id     : chr [1:1095] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date   : Date[1:1095], format: \"1999-01-01\" \"1999-01-02\" ... #>   .. ..$ Yearday: num [1:1095] 1 2 3 4 5 6 7 8 9 10 ... #>   .. ..$ medQJ  : num [1:1095] 1.75 1.78 1.84 1.84 1.92 ... #>   ..$ medQJC5      : tibble [1,095 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id     : chr [1:1095] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date   : Date[1:1095], format: \"1999-01-01\" \"1999-01-02\" ... #>   .. ..$ Yearday: num [1:1095] 1 2 3 4 5 6 7 8 9 10 ... #>   .. ..$ medQJ  : num [1:1095] 1.75 1.78 1.84 1.84 1.92 ... #>   .. ..$ medQJC5: num [1:1095] 1.77 1.79 1.83 1.85 1.89 ... #>   ..$ Q25A         : tibble [60 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id  : chr [1:60] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date: Date[1:60], format: \"1999-01-01\" \"2000-01-01\" ... #>   .. ..$ Q25A: num [1:60] NA 2.71 4.44 3.42 2.9 ... #>   ..$ Q50A         : tibble [60 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id  : chr [1:60] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date: Date[1:60], format: \"1999-01-01\" \"2000-01-01\" ... #>   .. ..$ Q50A: num [1:60] NA 2.49 3.42 2.54 2.32 ... #>   ..$ Q75A         : tibble [60 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id  : chr [1:60] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date: Date[1:60], format: \"1999-01-01\" \"2000-01-01\" ... #>   .. ..$ Q75A: num [1:60] NA 2.32 2.84 2.28 1.79 NA NA NA NA 1.91 ... #>   ..$ QA           : tibble [63 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id  : chr [1:63] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date: Date[1:63], format: \"1998-09-01\" \"1999-09-01\" ... #>   .. ..$ QA  : num [1:63] NA 2.35 3.55 2.99 2.5 ... #>   ..$ QJC10        : tibble [1,095 √ó 2] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id   : chr [1:1095] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ QJC10: num [1:1095] NA NA NA NA NA NA NA NA NA NA ... #>   ..$ QM           : tibble [36 √ó 4] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id   : chr [1:36] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date : Date[1:36], format: \"1999-01-01\" \"1999-02-01\" ... #>   .. ..$ Month: num [1:36] 1 2 3 4 5 6 7 8 9 10 ... #>   .. ..$ QM   : num [1:36] NA NA NA 2.37 2.31 ... #>   ..$ QSA_JJASO    : tibble [60 √ó 3] (S3: tbl_df/tbl/data.frame) #>   .. ..$ id       : chr [1:60] \"E645651001\" \"E645651001\" \"E645651001\" \"E645651001\" ... #>   .. ..$ Date     : Date[1:60], format: \"1999-06-01\" \"2000-06-01\" ... #>   .. ..$ QSA_JJASO: num [1:60] NA 2.38 3.41 2.5 2.03 ..."},{"path":"https://louis-heraut.github.io/CARD/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Louis H√©raut. Maintainer, author. √âric Sauquet. Contributor. Jean-Philippe Vidal. Contributor. Nathan Pellerin. Contributor. David Dorchies. Contributor.","code":""},{"path":"https://louis-heraut.github.io/CARD/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"H√©raut L (2025). CARD: CARD. R package version 2.0.0, https://louis-heraut.github.io/CARD/.","code":"@Manual{,   title = {CARD: CARD},   author = {Louis H√©raut},   year = {2025},   note = {R package version 2.0.0},   url = {https://louis-heraut.github.io/CARD/}, }"},{"path":"https://louis-heraut.github.io/CARD/index.html","id":"card-","dir":"","previous_headings":"","what":"CARD","title":"CARD","text":"CARD efficient user-friendly solution aggregating daily hydroclimatological time series data R, made possible use parameterization files. precisely, package aims regroup relevant aggregated hydroclimatological variable procedures CARD serves interface core aggregation process carried EXstat package. project carried National Research Institute Agriculture, Food Environment (Institut National de Recherche pour l‚ÄôAgriculture, l‚ÄôAlimentation et l‚ÄôEnvironnement, INRAE french) core MAKAHO won 2024 Open Science Research Data Award ‚ÄúCreating Conditions Reuse‚Äù category.","code":""},{"path":"https://louis-heraut.github.io/CARD/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"CARD","text":"latest development version R","code":"remotes::install_github(\"louis-heraut/CARD\")"},{"path":"https://louis-heraut.github.io/CARD/index.html","id":"how-to-use-card-","dir":"","previous_headings":"","what":"How to use CARD ?","title":"CARD","text":"user-friendly aggregation process, package regroup predefined parameterisation files called CARD. CARD represent one hydroclimatological aggregated variable. way don‚Äôt define complex parameters extract hydroclimatological variables. ‚Äôs , CARD want doesn‚Äôt exist, ‚Äôs easy create one based others.","code":""},{"path":"https://louis-heraut.github.io/CARD/index.html","id":"basic-workflow","dir":"","previous_headings":"How to use CARD ?","what":"Basic workflow","title":"CARD","text":"example, hydrology, want extract annual mean daily discharge QA hydrometric data can simply run return result list metadata extraction metaEX tibble result extraction dataEX tibble. Many CARDs available. want look every current possibilities, use CARD_list_all() function gives Based , can example filter variables topic get name available CARDs ","code":"install.packages(\"airGRdatasets\") library(dplyr)  data = tibble(airGRdatasets::A273011002$TS) %>%     mutate(code=\"A273011002\",            Date=as.Date(Date)) %>%     rename(Q=Qls) res = CARD_extraction(data, CARD_name=\"QA\") > res $metaEX # A tibble: 1 √ó 19   variable_en unit_en      name_en description_en method_en sampling_period_en   <chr>       <chr>        <chr>   <chr>          <chr>     <chr>              1 QA          m^{3}.s^{-1} Annual‚Ä¶ \"\"             1. annua‚Ä¶ 09-01, 08-31       # ‚Ñπ 13 more variables: topic_en <chr>, variable_fr <chr>, unit_fr <chr>, #   name_fr <chr>, description_fr <chr>, method_fr <chr>, #   sampling_period_fr <chr>, topic_fr <chr>, #   preferred_hydrological_month <dbl>, is_date <lgl>, to_normalise <lgl>, #   palette <chr>, script_path <chr>  $dataEX $dataEX$QA # A tibble: 21 √ó 3    code       Date          QA    <chr>      <date>     <dbl>  1 A273011002 1998-09-01   NA   2 A273011002 1999-09-01 7048.  3 A273011002 2000-09-01 6409.  4 A273011002 2001-09-01 6403.  5 A273011002 2002-09-01 4850.  6 A273011002 2003-09-01 3768.  7 A273011002 2004-09-01 5044.  8 A273011002 2005-09-01 4805.  9 A273011002 2006-09-01 7095. 10 A273011002 2007-09-01 5575. # ‚Ñπ 11 more rows # ‚Ñπ Use `print(n = ...)` to see more rows metaEX_all = CARD_list_all() > metaEX_all # A tibble: 565 √ó 20    variable_en     unit_en name_en description_en method_en sampling_period_en    <chr>           <chr>   <chr>   <chr>          <chr>     <chr>               1 ETPA            mm      Cumula‚Ä¶ \"\"             \"\"        09-01, 08-31        2 BFI_Wal         withou‚Ä¶ Basefl‚Ä¶ \"Ratio betwe‚Ä¶\" \"1. no ‚Ä¶\" NA                  3 BFM             withou‚Ä¶ Basefl‚Ä¶ \"\"             \"1. no ‚Ä¶\" NA                  4 delta{BFI}_LH_‚Ä¶ withou‚Ä¶ Change‚Ä¶ \"Ratio betwe‚Ä¶\" \"1. no ‚Ä¶\" NA                  5 delta{BFI}_LH_‚Ä¶ withou‚Ä¶ Change‚Ä¶ \"Ratio betwe‚Ä¶\" \"1. no ‚Ä¶\" NA                  6 delta{BFI}_LH_‚Ä¶ withou‚Ä¶ Change‚Ä¶ \"Ratio betwe‚Ä¶\" \"1. no ‚Ä¶\" NA                  7 delta{BFI}_Wal‚Ä¶ withou‚Ä¶ Change‚Ä¶ \"Ratio betwe‚Ä¶\" \"1. no ‚Ä¶\" NA                  8 delta{BFI}_Wal‚Ä¶ withou‚Ä¶ Change‚Ä¶ \"Ratio betwe‚Ä¶\" \"1. no ‚Ä¶\" NA                  9 delta{BFI}_Wal‚Ä¶ withou‚Ä¶ Change‚Ä¶ \"Ratio betwe‚Ä¶\" \"1. no ‚Ä¶\" NA                 10 delta{centerBF‚Ä¶ day     Averag‚Ä¶ \"Date when 5‚Ä¶\" \"1. ann‚Ä¶\" 09-01, 08-31       # ‚Ñπ 555 more rows # ‚Ñπ 14 more variables: topic_en <chr>, variable_fr <chr>, unit_fr <chr>, #   name_fr <chr>, description_fr <chr>, method_fr <chr>, #   sampling_period_fr <chr>, topic_fr <chr>, source <chr>, #   preferred_hydrological_month <int>, is_date <lgl>, to_normalise <lgl>, #   palette <chr>, script_path <chr> # ‚Ñπ Use `print(n = ...)` to see more rows metaEX_low_flow = dplyr::filter(metaEX_all, grepl(\"Low Flow\", topic_en)) metaEX_low_flow$variable_en"},{"path":"https://louis-heraut.github.io/CARD/index.html","id":"complex-workflow","dir":"","previous_headings":"How to use CARD ?","what":"Complex workflow","title":"CARD","text":"similar, complex way, can extract multiple variables time one discharge series, return","code":"# For one station data1 = tibble(airGRdatasets::A273011002$TS) %>%     mutate(code=\"A273011002\",            Date=as.Date(Date)) %>%     rename(Q_obs=Qls)  # and an other data2 = tibble(airGRdatasets::H622101001$TS) %>%     mutate(code=\"H622101001\",            Date=as.Date(Date)) %>%     rename(Q_obs=Qls) # make one tibble data = bind_rows(data1, data2)  # add some noise for mock simulation data data$Q_sim = data$Q_obs + rnorm(nrow(data), mean=0, sd=100)  # and perfom an extraction res = CARD_extraction(data,                       CARD_name=c(\"QA\", \"QMNA\", \"VCN10-5\"),                       suffix=c(\"obs\", \"sim\")) > res $metaEX # A tibble: 3 √ó 19   variable_en unit_en      name_en description_en method_en sampling_period_en   <chr>       <chr>        <chr>   <chr>          <chr>     <chr>              1 VCN10-5     m^{3}.s^{-1} Annual‚Ä¶ \"\"             \"1. no t‚Ä¶\" \"Month of maximum ‚Ä¶\" 2 QMNA        m^{3}.s^{-1} Annual‚Ä¶ \"\"             \"1. mont‚Ä¶\" \"Month of maximum ‚Ä¶\" 3 QA          m^{3}.s^{-1} Annual‚Ä¶ \"\"             \"1. annu‚Ä¶\" 09-01, 08-31       # ‚Ñπ 13 more variables: topic_en <chr>, variable_fr <chr>, unit_fr <chr>, #   name_fr <chr>, description_fr <chr>, method_fr <chr>, #   sampling_period_fr <chr>, topic_fr <chr>, #   preferred_hydrological_month <dbl>, is_date <lgl>, to_normalise <lgl>, #   script_path <chr>, palette <chr>  $dataEX $dataEX$`VCN10-5` # A tibble: 2 √ó 3   code       `VCN10-5_obs` `VCN10-5_sim`   <chr>              <dbl>         <dbl> 1 A273011002          914.          901. 2 H622101001         2770.         2769.  $dataEX$QMNA # A tibble: 40 √ó 4    code       Date       QMNA_obs QMNA_sim    <chr>      <date>        <dbl>    <dbl>  1 A273011002 1999-01-01    1050.    1070.  2 A273011002 2000-01-01    2586.    2569.  3 A273011002 2001-01-01    1401.    1408.  4 A273011002 2002-01-01    1463.    1454.  5 A273011002 2003-01-01    1182.    1167.  6 A273011002 2004-01-01    1362.    1354.  7 A273011002 2005-01-01    1245.    1264.  8 A273011002 2006-01-01    1770     1778.  9 A273011002 2007-01-01    1889.    1875. 10 A273011002 2008-01-01    1669.    1659. # ‚Ñπ 30 more rows # ‚Ñπ Use `print(n = ...)` to see more rows  $dataEX$QA # A tibble: 42 √ó 4    code       Date       QA_obs QA_sim    <chr>      <date>      <dbl>  <dbl>  1 A273011002 1998-09-01    NA     NA   2 A273011002 1999-09-01  7048.  7049.  3 A273011002 2000-09-01  6409.  6419.  4 A273011002 2001-09-01  6403.  6407.  5 A273011002 2002-09-01  4850.  4842.  6 A273011002 2003-09-01  3768.  3763.  7 A273011002 2004-09-01  5044.  5045.  8 A273011002 2005-09-01  4805.  4805.  9 A273011002 2006-09-01  7095.  7093. 10 A273011002 2007-09-01  5575.  5562. # ‚Ñπ 32 more rows # ‚Ñπ Use `print(n = ...)` to see more rows"},{"path":"https://louis-heraut.github.io/CARD/index.html","id":"custom-workflow","dir":"","previous_headings":"How to use CARD ?","what":"Custom workflow","title":"CARD","text":"Maybe can‚Äôt find CARD want want try customize one even create new one based another example. , get example CARD want local directory running create VCN10-5.R CARD \"CARD-WIP\" directory working directory. , can open R file , example, change metadata return period parameter 5 10 get VCN10-10 CARD, represents annual minimum 10-day mean daily discharge return period 10 years instead 5. extraction, simply run perform extraction CARDs CARD_path directory. want select specific variables extract custom CARD directory, just use CARD_name variable seen basic workflow section.","code":"CARD_management(CARD_name = c(\"VCN10-5\"), CARD_path = \"CARD-WIP\") res = CARD_extraction(data, CARD_name = NULL,                         CARD_path = \"CARD-WIP\")"},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/index.html","id":"inst__all__-directory","dir":"","previous_headings":"What is a CARD ?","what":"inst/__all__ directory","title":"CARD","text":"directory, can find different CARDs available, organized topic type aggregation: serie criteria. EXstat terminology, criterion aggregated variable retain temporal extension, unlike serie variable, maintains temporal extension even aggregation process. CARDs structure, exemplified annual average daily flow QA __all__/Flow/Mean_Flows/serie: CARDs separated 2 main parts: INFO PROCESS.","code":"#   ___                _  #  / __| __ _  _ _  __| | # | (__ / _` || '_|/ _` | #  \\___|\\__,_||_|  \\__,_| # Copyright 2022-2025 Louis H√©raut (louis.heraut@inrae.fr)*1 # # *1   INRAE, France # # This file is part of CARD R package. # # CARD R package is free software: you can redistribute it # and/or modify it under the terms of the GNU General Public License # as published by the Free Software Foundation, either version 3 of # the License, or (at your option) any later version. # # CARD R package is distributed in the hope that it will be # useful, but WITHOUT ANY WARRANTY; without even the implied warranty # of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. # See the GNU General Public License for more details. # # You should have received a copy of the GNU General Public License # along with CARD R package. # If not, see <https://www.gnu.org/licenses/>.   ## INFO ______________________________________________________________ ### English __________________________________________________________ CARD$P.variable_en = \"QA\" CARD$P.unit_en = \"m^{3}.s^{-1}\" CARD$P.name_en = \"Annual mean daily discharge\" CARD$P.description_en = \"\" CARD$P.method_en = \"1. annual aggregation [09-01, 08-31] - mean\" CARD$P.sampling_period_en = \"09-01, 08-31\" CARD$P.topic_en = \"Flow, Mean Flows, Intensity\"  ### French ___________________________________________________________ CARD$P.variable_fr = \"QA\" CARD$P.unit_fr = \"m^{3}.s^{-1}\" CARD$P.name_fr = \"Moyenne annuelle du d√©bit journalier\" CARD$P.description_fr = \"\" CARD$P.method_fr = \"1. agr√©gation annuelle [01-09, 31-08] - moyenne\" CARD$P.sampling_period_fr = \"01-09, 31-08\" CARD$P.topic_fr = \"D√©bit, Moyennes Eaux, Intensit√©\"  ### Global ___________________________________________________________ CARD$P.preferred_hydrological_month = 9 CARD$P.is_date = FALSE CARD$P.to_normalise = TRUE CARD$P.palette = \"#452C1A #7F4A23 #B3762A #D4B86A #EFE0B0 #BCE6DB #7ACEB9 #449C93 #2A6863 #193830\"   ## PROCESS ___________________________________________________________ ### P1 _______________________________________________________________ CARD$P1.funct = list(QA=mean) CARD$P1.funct_args = list(\"Q\", na.rm=TRUE) CARD$P1.time_step = \"year\" CARD$P1.sampling_period = \"09-01\" CARD$P1.NApct_lim = 3 CARD$P1.NAyear_lim = 10"},{"path":"https://louis-heraut.github.io/CARD/index.html","id":"info","dir":"","previous_headings":"What is a CARD ? > inst/__all__ directory","what":"INFO","title":"CARD","text":"part, can find necessary information variable represented CARD. English French versions parameters unit, name, description. Global info general info need translation. information merely informational; serves metadata EXstat. parameters optional default value based __default__.R CARD, can find inst directory. However, definitely encouraged fill .","code":""},{"path":"https://louis-heraut.github.io/CARD/index.html","id":"process","dir":"","previous_headings":"What is a CARD ? > inst/__all__ directory","what":"PROCESS","title":"CARD","text":"PROCESS part, find steps needed extract desired variable. parameters listed parameters can use EXstat‚Äôs process_extraction() function. , one step need calculate yearly mean type aggregation. However, example, can add another step like: now modulus flow, average annual average daily flow, labeled meanQA.","code":"### P2 _______________________________________________________________ CARD$P2.funct = list(\"meanQA\"=mean) CARD$P2.funct_args = list(\"QA\", na.rm=TRUE) CARD$P2.time_step = \"none\""},{"path":"https://louis-heraut.github.io/CARD/index.html","id":"r-directory","dir":"","previous_headings":"What is a CARD ?","what":"R/ directory","title":"CARD","text":"directory, can find different functions needed aggregation process CARDs. ordered type application, may take time search understand available . can modify add function. directory also contains core functions CARD management CARD extraction, allow users interact CARD formatting connection EXstat package.","code":""},{"path":"https://louis-heraut.github.io/CARD/index.html","id":"you-need-a-new-card-","dir":"","previous_headings":"What is a CARD ?","what":"You need a new CARD ?","title":"CARD","text":"Good Solution : Search existing request issue list one asked , create new issue. Better Solution : Along issue submission, provide minimal CARD file informative metadata filled . Best Solution : Create test CARD submit pull request. fastest way get new CARD.","code":""},{"path":"https://louis-heraut.github.io/CARD/index.html","id":"faq","dir":"","previous_headings":"","what":"FAQ","title":"CARD","text":"üì¨ ‚Äî like upgrade / question / Need reach Feel free open issue ! ‚Äôm actively maintaining project, ‚Äôll best respond quickly. ‚Äôm also reachable institutional INRAE email -depth discussions. üõ†Ô∏è ‚Äî found bug - Good Solution : Search existing issue list, one reported , create new issue ! - Better Solution : Along issue submission, provide minimal reproducible code sample. - Best Solution : Fix issue submit pull request. fastest way get bug fixed. üöÄ ‚Äî Want contribute ? don‚Äôt know start, open issue. want try , start also opening issue let know ‚Äôre working something ? : Fork repository Clone fork locally make changes (even better, create new branch modifications) Push fork verify everything works expected Open Pull Request GitHub describe Wait review future development, keep fork updated using GitHub ‚ÄúSync fork‚Äù functionality pulling changes original repo (even via remote upstream ‚Äôre comfortable Git). Otherwise, feel free delete fork keep things tidy ! ‚Äôre connected work, reach via email see can collaborate closely repo adding collaborator ! Refer CONTRIBUTING file contribution guidelines help.","code":""},{"path":"https://louis-heraut.github.io/CARD/index.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"CARD","text":"Please note project released Contributor Code Conduct. participating project agree abide terms.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/BFS.html","id":null,"dir":"Reference","previous_headings":"","what":"BFS - Baseflow Separation ‚Äî BFS","title":"BFS - Baseflow Separation ‚Äî BFS","text":"Performs baseflow separation streamflow data using either Wallingford method Lyne & Hollick digital filter approach. Wallingford method identifies turning points hydrograph, Lyne & Hollick method applies recursive digital filter.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/BFS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"BFS - Baseflow Separation ‚Äî BFS","text":"","code":"BFS(Q, d = 5, w = 0.9, a = 0.925, passes = 3, method = \"Wal\")"},{"path":"https://louis-heraut.github.io/CARD/reference/BFS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"BFS - Baseflow Separation ‚Äî BFS","text":"Q Numeric vector discharge (streamflow) values. Missing values (NA) allowed. d Integer specifying window size (days) identifying minima Wallingford method. Default 5. w Numeric weighting factor (0-1) used Wallingford method identify turning points. Default 0.9. Numeric filter parameter (0-1) Lyne & Hollick method, higher values result smoother baseflow. Default 0.925. passes Integer specifying number forward/backward passes Lyne & Hollick method. Default 3 (recommended optimal results). method Character specifying separation method: \"Wal\" Wallingford \"LH\" Lyne & Hollick. Default \"Wal\".","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/BFS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"BFS - Baseflow Separation ‚Äî BFS","text":"numeric vector baseflow values corresponding input discharge values. Returns NA input contains NA values insufficient turning points found (Wallingford method).","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/BFS.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"BFS - Baseflow Separation ‚Äî BFS","text":"Wallingford method (method = \"Wal\"): hydrograph divided d-day segments minimum flow segment identified Turning points identified w*Qmin < adjacent minima Baseflow interpolated turning points Lyne & Hollick method (method = \"LH\"): Applies recursive digital filter parameter Performs multiple forward/backward passes (specified passes) filter equation : SFi = *SFi-1 + (1+)/2 * (Qi-Qi-1)","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/BFS.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"BFS - Baseflow Separation ‚Äî BFS","text":"Gustard, ., Bullock, ., & Dixon, J. M. (1992). Low Flow Estimation United Kingdom. Institute Hydrology Report . 108. Wallingford, UK. Lyne, V., & Hollick, M. (1979). Stochastic time-variable rainfall-runoff modelling. Institute Engineers Australia National Conference, 89-93.","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/BFS.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"BFS - Baseflow Separation ‚Äî BFS","text":"","code":"# Load sample streamflow data Q <- c(10, 12, 15, 20, 18, 16, 14, 12, 10, 9)  # Streamflow  # Apply Wallingford method baseflow_wal <- BFS(Q, method = \"Wal\")  # Apply Lyne & Hollick method with custom parameters baseflow_lh <- BFS(Q, method = \"LH\", a = 0.95, passes = 5)  # Plot results plot(Q, type = \"l\") lines(baseflow_wal, col = \"blue\") lines(baseflow_lh, col = \"red\")"},{"path":"https://louis-heraut.github.io/CARD/reference/CARD_extraction.html","id":null,"dir":"Reference","previous_headings":"","what":"CARD_extraction ‚Äî CARD_extraction","title":"CARD_extraction ‚Äî CARD_extraction","text":"Extracts variables time series (example, yearly mean time series) using CARD parameterization files.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/CARD_extraction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CARD_extraction ‚Äî CARD_extraction","text":"","code":"CARD_extraction(   data,   CARD_name = c(\"QA\", \"QJXA\"),   CARD_path = NULL,   period_default = NULL,   suffix = NULL,   suffix_delimiter = \"_\",   cancel_lim = FALSE,   simplify = FALSE,   expand_overwrite = NULL,   sampling_period_overwrite = NULL,   rmNApct = TRUE,   rm_duplicates = FALSE,   extract_only_metadata = FALSE,   dev = FALSE,   verbose = FALSE )"},{"path":"https://louis-heraut.github.io/CARD/reference/CARD_extraction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"CARD_extraction ‚Äî CARD_extraction","text":"data Input data format tibble tibble package. needs : one column Date regularly spaced unique time serie. one time serie, least one column needs character string names time series order identify . one column identifier given, used order identify unique time serie. least one column numeric (logical) process variable extraction perform. numerical column can leave useless, suppressed. e.g.   CARD_name vector character strings specify variables want extract. See CARD_list_all() get variable names. default, c(\"QA\", \"QJXA\"). NULL, variable extracted, avoid value except extract_only_metadata = TRUE custom CARD_path directory. CARD_path optional character string path search custom CARDs created CARD_management function. default, NULL order get default CARD variable parameters. period_default vector two dates (two unambiguous character strings can coerced dates) restrict period analysis. example, can c(\"1950-01-01\", \"2020-12-31\") select data 1st January 1950 end December 2020. CARD can specific period parameter overide period_default argument. default option period_default=NULL, considers available data time serie. suffix character string vector representing suffixes appended column names extracted variables. parameter allows handling multiple extraction scenarios. example, cumbersome case can unique function apply multiple list column. possible give funct=list(QA_obs=mean, QA_sim=mean) funct_args=list(list(\"Q_obs\", na.rm=TRUE), list(\"Q_sim\", na.rm=TRUE)) simply funct=list(QA=mean) funct_args=list(\"Q\", na.rm=TRUE) suffix=c(\"obs\", \"sim\"). two approach give result. Default NULL. suffix_delimiter character string specifies delimiter use variable name suffix NULL. default \"_\". cancel_lim logical specify whether cancel NA percentage limits CARDs. Default FALSE. simplify logical specify whether simplify extracted data joining tibble extracted CARDs. Usefull extracted variable temporal extension. Default \"FALSE\". expand_overwrite logical NULL. TRUE, expand output tibble list tibble extracted variable suffix. Default NULL conserve value specified CARDs used. sampling_period_overwrite character string vector two character strings indicate sample data time step defined time_step. Hence, choice argument needs link choice time step. example, yearly extraction time_step set \"year\", sampling_period needs formated %m-%d (month - day year) order indicate start sampling data current year. precisly, time_step=\"year\" sampling_period=\"03-19\", funct apply every data 3rd march year 2nd march following one. way, possible create sub-year sampling vector two character strings sampling_period=c(\"02-01\", \"07-31\") order process data date 1st february 31th jully year. available now monthly (seasonal) extraction, sampling_period needs give day month, example sampling_period=\"10\" extract data 10th month 9th following month. Default NULL conserve value specified CARDs used. rmNApct logical. NApct column, shows percentage missing values output, removed ? Default TRUE. rm_duplicates logical. duplicate time series values automatically removed ? Default FALSE. extract_only_metadata logical. TRUE, metadata CARD extracted. case, use data=NULL. Default FALSE. dev logical TRUE, development mode enabled. Default FALSE. verbose logical. intermediate messages printed execution function ? Default FALSE.","code":"> data A tibble: 201 √ó 4    time         Q_obs  Q_sim  ID    <date>       <dbl>  <dbl>  <chr> 1   2000-02-10   10     97.8  serie 1 2   2000-02-11   19    -20.5  serie 1 3   2000-02-12   13    -76.9  serie 1 4   2000-02-13   15    -86.0  serie 1     ... 103 2001-01-01  1.3     1988  serie 2 104 2001-01-02  1.2      109  serie 2 105 2001-01-03  1.0       90  serie 2 106 2001-01-04  1.1       91  serie 2     ..."},{"path":"https://louis-heraut.github.io/CARD/reference/CARD_extraction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"CARD_extraction ‚Äî CARD_extraction","text":"list two tibbles. dataEX tibble, contains extracted variable, named list tibbles extracted variable expand_overwrite TRUE. metaEX tibble, contains metadata extraction CARDs.","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/CARD_extraction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"CARD_extraction ‚Äî CARD_extraction","text":"","code":"library(CARD)  # Get all the available variables metaEX_all = CARD_list_all() metaEX_all #> # A tibble: 563 √ó 23 #>    CARD_name          variable_en       unit_en name_en description_en method_en #>    <chr>              <chr>             <chr>   <chr>   <chr>          <chr>     #>  1 ETPA               ETPA              mm      Cumula‚Ä¶ \"\"             \"\"        #>  2 BFI-Wal            BFI-Wal           withou‚Ä¶ Basefl‚Ä¶ \"Ratio betwee‚Ä¶ \"1. no t‚Ä¶ #>  3 BFM                BFM               withou‚Ä¶ Basefl‚Ä¶ \"\"             \"1. no t‚Ä¶ #>  4 delta{centerBF}_H1 delta{centerBF}_‚Ä¶ day     Averag‚Ä¶ \"Date when 50‚Ä¶ \"1. annu‚Ä¶ #>  5 delta{centerBF}_H2 delta{centerBF}_‚Ä¶ day     Averag‚Ä¶ \"Date when 50‚Ä¶ \"1. annu‚Ä¶ #>  6 delta{centerBF}_H3 delta{centerBF}_‚Ä¶ day     Averag‚Ä¶ \"Date when 50‚Ä¶ \"1. annu‚Ä¶ #>  7 delta{dtBF}_H1     delta{dtBF}_H1    day     Averag‚Ä¶ \"Duration bet‚Ä¶ \"1. annu‚Ä¶ #>  8 delta{dtBF}_H2     delta{dtBF}_H2    day     Averag‚Ä¶ \"Duration bet‚Ä¶ \"1. annu‚Ä¶ #>  9 delta{dtBF}_H3     delta{dtBF}_H3    day     Averag‚Ä¶ \"Duration bet‚Ä¶ \"1. annu‚Ä¶ #> 10 delta{endBF}_H1    delta{endBF}_H1   day     Averag‚Ä¶ \"Date when 90‚Ä¶ \"1. annu‚Ä¶ #> # ‚Ñπ 553 more rows #> # ‚Ñπ 17 more variables: sampling_period_en <chr>, topic_en <chr>, #> #   variable_fr <chr>, unit_fr <chr>, name_fr <chr>, description_fr <chr>, #> #   method_fr <chr>, sampling_period_fr <chr>, topic_fr <chr>, #> #   is_experimental <lgl>, input_vars <chr>, source <chr>, #> #   preferred_sampling_period <chr>, is_date <lgl>, to_normalise <lgl>, #> #   palette <chr>, script_path <chr>  # Create mock data Start = as.Date(\"2001-03-02\") End = as.Date(\"2024-11-30\") Date = seq.Date(Start, End, by=\"day\") data = dplyr::tibble(time=Date,                      Q=as.numeric(Date),                      id=\"serie 1\")  # Do a direct extraction res = CARD_extraction(data, CARD_name=c(\"QA\", \"QMNA\"), verbose=TRUE) #> [1] \"Computes QMNA\" #> [1] \"Process 1/2\" #> [1] \"EXTRACTION PROCESS                                \" #> [1] \"‚îú‚îÄ‚îÄ Missing year                                  \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Checking missing continuous periods       \" #> [1] \"‚îÇ       longer than 10 years                      \" #> [1] \"‚îú‚îÄ‚îÄ Period                                        \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Selecting all the data                    \" #> [1] \"‚îú‚îÄ‚îÄ Sample period                                 \" #> [1] \"‚îÇ   ‚îú‚îÄ‚îÄ Default sample period used                \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Fixing sample period                      \" #> [1] \"‚îÇ       ‚îú‚îÄ‚îÄ Only start of the sample period was   \" #> [1] \"‚îÇ       ‚îÇ   given                                 \" #> [1] \"‚îÇ       ‚îú‚îÄ‚îÄ Every time series have the same       \" #> [1] \"‚îÇ       ‚îÇ   sample period                         \" #> [1] \"‚îÇ       ‚îî‚îÄ‚îÄ All : 01 / 30                         \" #> [1] \"‚îú‚îÄ‚îÄ Monthly extraction along years                \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Preparing date data for the extraction    \" #> [1] \"‚îÇ       ‚îú‚îÄ‚îÄ Get general sample info               \" #> [1] \"‚îÇ       ‚îú‚îÄ‚îÄ Computing of time indicators for      \" #> [1] \"‚îÇ       ‚îÇ   each time serie                       \" #> [1] \"‚îÇ       ‚îú‚îÄ‚îÄ Get number of missing data for start  \" #> [1] \"‚îÇ       ‚îÇ   and end                               \" #> [1] \"‚îÇ       ‚îî‚îÄ‚îÄ Create each group                     \" #> [1] \"‚îú‚îÄ‚îÄ Grouping data                                 \" #> [1] \"‚îú‚îÄ‚îÄ Application of the function                   \" #> [1] \"‚îú‚îÄ‚îÄ Cleaning extracted tibble                     \" #> [1] \"‚îÇ   ‚îú‚îÄ‚îÄ Manage possible infinite values           \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Recreate a date vector and add value for  \" #> [1] \"‚îÇ       NApct computing                           \" #> [1] \"‚îú‚îÄ‚îÄ NA management                                 \" #> [1] \"‚îÇ   ‚îú‚îÄ‚îÄ Compute NA percentage                     \" #> [1] \"‚îÇ   ‚îú‚îÄ‚îÄ Removing data if NA percentage is         \" #> [1] \"‚îÇ   ‚îÇ   strictly above 3 %                        \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Cleaning NA percentage info               \" #> [1] \"‚îî‚îÄ‚îÄ Last cleaning and formating for output        \" #> [1] \"    ‚îú‚îÄ‚îÄ Rename column                             \" #> [1] \"    ‚îú‚îÄ‚îÄ Keeping only the needed data : all        \" #> [1] \"    ‚îî‚îÄ‚îÄ Return data                               \" #> # A tibble: 8,675 √ó 4 #>    id      time           Q   QMA #>    <chr>   <date>     <dbl> <dbl> #>  1 serie 1 2001-03-02 11383    NA #>  2 serie 1 2001-03-03 11384    NA #>  3 serie 1 2001-03-04 11385    NA #>  4 serie 1 2001-03-05 11386    NA #>  5 serie 1 2001-03-06 11387    NA #>  6 serie 1 2001-03-07 11388    NA #>  7 serie 1 2001-03-08 11389    NA #>  8 serie 1 2001-03-09 11390    NA #>  9 serie 1 2001-03-10 11391    NA #> 10 serie 1 2001-03-11 11392    NA #> # ‚Ñπ 8,665 more rows #> [1] \"Process 2/2\" #> [1] \"EXTRACTION PROCESS                                \" #> [1] \"‚îú‚îÄ‚îÄ Period                                        \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Selecting all the data                    \" #> [1] \"‚îú‚îÄ‚îÄ Sample period                                 \" #> [1] \"‚îÇ   ‚îú‚îÄ‚îÄ Fixing sample period for each time series \" #> [1] \"‚îÇ       ‚îú‚îÄ‚îÄ Every time series have the same       \" #> [1] \"‚îÇ       ‚îÇ   sample period                         \" #> [1] \"‚îÇ       ‚îî‚îÄ‚îÄ All : 11-01 / 10-31                   \" #> [1] \"‚îú‚îÄ‚îÄ Yearly extraction                             \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Preparing date data for the extraction    \" #> [1] \"‚îÇ       ‚îú‚îÄ‚îÄ Get general sample info               \" #> [1] \"‚îÇ       ‚îú‚îÄ‚îÄ Computing of time indicators for      \" #> [1] \"‚îÇ       ‚îÇ   each time serie                       \" #> [1] \"‚îÇ       ‚îú‚îÄ‚îÄ Get number of missing data for start  \" #> [1] \"‚îÇ       ‚îÇ   and end                               \" #> [1] \"‚îÇ       ‚îî‚îÄ‚îÄ Create each group                     \" #> [1] \"‚îú‚îÄ‚îÄ Grouping data                                 \" #> [1] \"‚îú‚îÄ‚îÄ Application of the function                   \" #> [1] \"‚îú‚îÄ‚îÄ Cleaning extracted tibble                     \" #> [1] \"‚îÇ   ‚îú‚îÄ‚îÄ Manage possible infinite values           \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Recreate a date vector and add value for  \" #> [1] \"‚îÇ       NApct computing                           \" #> [1] \"‚îú‚îÄ‚îÄ NA management                                 \" #> [1] \"‚îÇ   ‚îú‚îÄ‚îÄ Compute NA percentage                     \" #> [1] \"‚îÇ   ‚îú‚îÄ‚îÄ Removing data if NA percentage is         \" #> [1] \"‚îÇ   ‚îÇ   strictly above 3 %                        \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Cleaning NA percentage info               \" #> [1] \"‚îî‚îÄ‚îÄ Last cleaning and formating for output        \" #> [1] \"    ‚îú‚îÄ‚îÄ Rename column                             \" #> [1] \"    ‚îî‚îÄ‚îÄ Return data                               \" #> # A tibble: 25 √ó 3 #>    id      time         QMNA #>    <chr>   <date>      <dbl> #>  1 serie 1 2000-11-01    NA  #>  2 serie 1 2001-11-01 11642. #>  3 serie 1 2002-11-01 12006. #>  4 serie 1 2003-11-01 12372. #>  5 serie 1 2004-11-01 12738. #>  6 serie 1 2005-11-01 13102. #>  7 serie 1 2006-11-01 13468. #>  8 serie 1 2007-11-01 13832. #>  9 serie 1 2008-11-01 14198. #> 10 serie 1 2009-11-01 14564. #> # ‚Ñπ 15 more rows #> [1] \"Computes QA\" #> [1] \"Process 1/1\" #> [1] \"EXTRACTION PROCESS                                \" #> [1] \"‚îú‚îÄ‚îÄ Missing year                                  \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Checking missing continuous periods       \" #> [1] \"‚îÇ       longer than 10 years                      \" #> [1] \"‚îú‚îÄ‚îÄ Period                                        \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Selecting all the data                    \" #> [1] \"‚îú‚îÄ‚îÄ Sample period                                 \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Fixing sample period                      \" #> [1] \"‚îÇ       ‚îú‚îÄ‚îÄ Only start of the sample period was   \" #> [1] \"‚îÇ       ‚îÇ   given                                 \" #> [1] \"‚îÇ       ‚îú‚îÄ‚îÄ Every time series have the same       \" #> [1] \"‚îÇ       ‚îÇ   sample period                         \" #> [1] \"‚îÇ       ‚îî‚îÄ‚îÄ All : 09-01 / 08-31                   \" #> [1] \"‚îú‚îÄ‚îÄ Yearly extraction                             \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Preparing date data for the extraction    \" #> [1] \"‚îÇ       ‚îú‚îÄ‚îÄ Get general sample info               \" #> [1] \"‚îÇ       ‚îú‚îÄ‚îÄ Computing of time indicators for      \" #> [1] \"‚îÇ       ‚îÇ   each time serie                       \" #> [1] \"‚îÇ       ‚îú‚îÄ‚îÄ Get number of missing data for start  \" #> [1] \"‚îÇ       ‚îÇ   and end                               \" #> [1] \"‚îÇ       ‚îî‚îÄ‚îÄ Create each group                     \" #> [1] \"‚îú‚îÄ‚îÄ Grouping data                                 \" #> [1] \"‚îú‚îÄ‚îÄ Application of the function                   \" #> [1] \"‚îú‚îÄ‚îÄ Cleaning extracted tibble                     \" #> [1] \"‚îÇ   ‚îú‚îÄ‚îÄ Manage possible infinite values           \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Recreate a date vector and add value for  \" #> [1] \"‚îÇ       NApct computing                           \" #> [1] \"‚îú‚îÄ‚îÄ NA management                                 \" #> [1] \"‚îÇ   ‚îú‚îÄ‚îÄ Compute NA percentage                     \" #> [1] \"‚îÇ   ‚îú‚îÄ‚îÄ Removing data if NA percentage is         \" #> [1] \"‚îÇ   ‚îÇ   strictly above 3 %                        \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Cleaning NA percentage info               \" #> [1] \"‚îî‚îÄ‚îÄ Last cleaning and formating for output        \" #> [1] \"    ‚îú‚îÄ‚îÄ Rename column                             \" #> [1] \"    ‚îî‚îÄ‚îÄ Return data                               \" #> # A tibble: 25 √ó 3 #>    id      time           QA #>    <chr>   <date>      <dbl> #>  1 serie 1 2000-09-01    NA  #>  2 serie 1 2001-09-01 11748  #>  3 serie 1 2002-09-01 12113  #>  4 serie 1 2003-09-01 12478. #>  5 serie 1 2004-09-01 12844  #>  6 serie 1 2005-09-01 13209  #>  7 serie 1 2006-09-01 13574  #>  8 serie 1 2007-09-01 13940. #>  9 serie 1 2008-09-01 14305  #> 10 serie 1 2009-09-01 14670  #> # ‚Ñπ 15 more rows res #> $metaEX #> # A tibble: 2 √ó 21 #>   variable_en unit_en      name_en   description_en method_en sampling_period_en #>   <chr>       <chr>        <chr>     <chr>          <chr>     <chr>              #> 1 QMNA        m^{3}.s^{-1} Annual m‚Ä¶ \"\"             \"1. mont‚Ä¶ Month of maximum ‚Ä¶ #> 2 QA          m^{3}.s^{-1} Annual m‚Ä¶ \"\"             \"1. annu‚Ä¶ 09-01, 08-31       #> # ‚Ñπ 15 more variables: topic_en <chr>, variable_fr <chr>, unit_fr <chr>, #> #   name_fr <chr>, description_fr <chr>, method_fr <chr>, #> #   sampling_period_fr <chr>, topic_fr <chr>, is_experimental <lgl>, #> #   input_vars <chr>, preferred_sampling_period <chr>, is_date <lgl>, #> #   to_normalise <lgl>, palette <chr>, script_path <chr> #>  #> $dataEX #> $dataEX$QMNA #> # A tibble: 25 √ó 3 #>    id      time         QMNA #>    <chr>   <date>      <dbl> #>  1 serie 1 2000-11-01    NA  #>  2 serie 1 2001-11-01 11642. #>  3 serie 1 2002-11-01 12006. #>  4 serie 1 2003-11-01 12372. #>  5 serie 1 2004-11-01 12738. #>  6 serie 1 2005-11-01 13102. #>  7 serie 1 2006-11-01 13468. #>  8 serie 1 2007-11-01 13832. #>  9 serie 1 2008-11-01 14198. #> 10 serie 1 2009-11-01 14564. #> # ‚Ñπ 15 more rows #>  #> $dataEX$QA #> # A tibble: 25 √ó 3 #>    id      time           QA #>    <chr>   <date>      <dbl> #>  1 serie 1 2000-09-01    NA  #>  2 serie 1 2001-09-01 11748  #>  3 serie 1 2002-09-01 12113  #>  4 serie 1 2003-09-01 12478. #>  5 serie 1 2004-09-01 12844  #>  6 serie 1 2005-09-01 13209  #>  7 serie 1 2006-09-01 13574  #>  8 serie 1 2007-09-01 13940. #>  9 serie 1 2008-09-01 14305  #> 10 serie 1 2009-09-01 14670  #> # ‚Ñπ 15 more rows #>  #>   # Or find the closest CARD variable that interests you CARD_management(CARD_name=c(\"VCN10-5\"),                 CARD_path=\"CARD-WIP\",                 overwrite=TRUE) # Personalise it in the created  `\"CARD-WIP\"` directory (for example change the return period) # And perform a custom extraction res = CARD_extraction(data, CARD_name=NULL,                       CARD_path=\"CARD-WIP\",                       verbose=TRUE) #> [1] \"Computes VCN10-5\" #> [1] \"Process 1/3\" #> [1] \"EXTRACTION PROCESS                                \" #> [1] \"‚îú‚îÄ‚îÄ Missing year                                  \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Checking missing continuous periods       \" #> [1] \"‚îÇ       longer than 10 years                      \" #> [1] \"‚îú‚îÄ‚îÄ Period                                        \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Selecting all the data                    \" #> [1] \"‚îú‚îÄ‚îÄ Sample period                                 \" #> [1] \"‚îÇ   ‚îú‚îÄ‚îÄ Default sample period used                \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Fixing sample period                      \" #> [1] \"‚îÇ       ‚îú‚îÄ‚îÄ Only start of the sample period was   \" #> [1] \"‚îÇ       ‚îÇ   given                                 \" #> [1] \"‚îÇ       ‚îú‚îÄ‚îÄ Every time series have the same       \" #> [1] \"‚îÇ       ‚îÇ   sample period                         \" #> [1] \"‚îÇ       ‚îî‚îÄ‚îÄ All : 01-01 / 12-31                   \" #> [1] \"‚îú‚îÄ‚îÄ None extraction                               \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Preparing date data for the extraction    \" #> [1] \"‚îÇ       ‚îú‚îÄ‚îÄ Get general sample info               \" #> [1] \"‚îú‚îÄ‚îÄ Grouping data                                 \" #> [1] \"‚îú‚îÄ‚îÄ Application of the function                   \" #> [1] \"‚îú‚îÄ‚îÄ Cleaning extracted tibble                     \" #> [1] \"‚îÇ   ‚îú‚îÄ‚îÄ Manage possible infinite values           \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Recreate a date vector and add value for  \" #> [1] \"‚îÇ       NApct computing                           \" #> [1] \"‚îú‚îÄ‚îÄ NA management                                 \" #> [1] \"‚îÇ   ‚îú‚îÄ‚îÄ Compute NA percentage                     \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Cleaning NA percentage info               \" #> [1] \"‚îî‚îÄ‚îÄ Last cleaning and formating for output        \" #> [1] \"    ‚îú‚îÄ‚îÄ Rename column                             \" #> [1] \"    ‚îú‚îÄ‚îÄ Keeping only the needed data : all        \" #> [1] \"    ‚îî‚îÄ‚îÄ Return data                               \" #> # A tibble: 8,675 √ó 4 #>    id      time           Q   VC10 #>    <chr>   <date>     <dbl>  <dbl> #>  1 serie 1 2001-03-02 11383    NA  #>  2 serie 1 2001-03-03 11384    NA  #>  3 serie 1 2001-03-04 11385    NA  #>  4 serie 1 2001-03-05 11386    NA  #>  5 serie 1 2001-03-06 11387 11388. #>  6 serie 1 2001-03-07 11388 11388. #>  7 serie 1 2001-03-08 11389 11390. #>  8 serie 1 2001-03-09 11390 11390. #>  9 serie 1 2001-03-10 11391 11392. #> 10 serie 1 2001-03-11 11392 11392. #> # ‚Ñπ 8,665 more rows #> [1] \"Process 2/3\" #> [1] \"EXTRACTION PROCESS                                \" #> [1] \"‚îú‚îÄ‚îÄ Period                                        \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Selecting all the data                    \" #> [1] \"‚îú‚îÄ‚îÄ Sample period                                 \" #> [1] \"‚îÇ   ‚îú‚îÄ‚îÄ Fixing sample period for each time series \" #> [1] \"‚îÇ       ‚îú‚îÄ‚îÄ Every time series have the same       \" #> [1] \"‚îÇ       ‚îÇ   sample period                         \" #> [1] \"‚îÇ       ‚îî‚îÄ‚îÄ All : 11-01 / 10-31                   \" #> [1] \"‚îú‚îÄ‚îÄ Yearly extraction                             \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Preparing date data for the extraction    \" #> [1] \"‚îÇ       ‚îú‚îÄ‚îÄ Get general sample info               \" #> [1] \"‚îÇ       ‚îú‚îÄ‚îÄ Computing of time indicators for      \" #> [1] \"‚îÇ       ‚îÇ   each time serie                       \" #> [1] \"‚îÇ       ‚îú‚îÄ‚îÄ Get number of missing data for start  \" #> [1] \"‚îÇ       ‚îÇ   and end                               \" #> [1] \"‚îÇ       ‚îî‚îÄ‚îÄ Create each group                     \" #> [1] \"‚îú‚îÄ‚îÄ Grouping data                                 \" #> [1] \"‚îú‚îÄ‚îÄ Application of the function                   \" #> [1] \"‚îú‚îÄ‚îÄ Cleaning extracted tibble                     \" #> [1] \"‚îÇ   ‚îú‚îÄ‚îÄ Manage possible infinite values           \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Recreate a date vector and add value for  \" #> [1] \"‚îÇ       NApct computing                           \" #> [1] \"‚îú‚îÄ‚îÄ NA management                                 \" #> [1] \"‚îÇ   ‚îú‚îÄ‚îÄ Compute NA percentage                     \" #> [1] \"‚îÇ   ‚îú‚îÄ‚îÄ Removing data if NA percentage is         \" #> [1] \"‚îÇ   ‚îÇ   strictly above 3 %                        \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Cleaning NA percentage info               \" #> [1] \"‚îî‚îÄ‚îÄ Last cleaning and formating for output        \" #> [1] \"    ‚îú‚îÄ‚îÄ Rename column                             \" #> [1] \"    ‚îî‚îÄ‚îÄ Return data                               \" #> # A tibble: 25 √ó 3 #>    id      time        VCN10 #>    <chr>   <date>      <dbl> #>  1 serie 1 2000-11-01    NA  #>  2 serie 1 2001-11-01 11628. #>  3 serie 1 2002-11-01 11992. #>  4 serie 1 2003-11-01 12358. #>  5 serie 1 2004-11-01 12724. #>  6 serie 1 2005-11-01 13088. #>  7 serie 1 2006-11-01 13454. #>  8 serie 1 2007-11-01 13818. #>  9 serie 1 2008-11-01 14184. #> 10 serie 1 2009-11-01 14550. #> # ‚Ñπ 15 more rows #> [1] \"Process 3/3\" #> [1] \"EXTRACTION PROCESS                                \" #> [1] \"‚îú‚îÄ‚îÄ Period                                        \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Selecting all the data                    \" #> [1] \"‚îú‚îÄ‚îÄ Sample period                                 \" #> [1] \"‚îÇ   ‚îú‚îÄ‚îÄ Default sample period used                \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Fixing sample period                      \" #> [1] \"‚îÇ       ‚îú‚îÄ‚îÄ Only start of the sample period was   \" #> [1] \"‚îÇ       ‚îÇ   given                                 \" #> [1] \"‚îÇ       ‚îú‚îÄ‚îÄ Every time series have the same       \" #> [1] \"‚îÇ       ‚îÇ   sample period                         \" #> [1] \"‚îÇ       ‚îî‚îÄ‚îÄ All : 01-01 / 12-31                   \" #> [1] \"‚îú‚îÄ‚îÄ None extraction                               \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Preparing date data for the extraction    \" #> [1] \"‚îÇ       ‚îú‚îÄ‚îÄ Get general sample info               \" #> [1] \"‚îú‚îÄ‚îÄ Grouping data                                 \" #> [1] \"‚îú‚îÄ‚îÄ Application of the function                   \" #> [1] \"‚îú‚îÄ‚îÄ Cleaning extracted tibble                     \" #> [1] \"‚îÇ   ‚îú‚îÄ‚îÄ Manage possible infinite values           \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Recreate a date vector and add value for  \" #> [1] \"‚îÇ       NApct computing                           \" #> [1] \"‚îú‚îÄ‚îÄ NA management                                 \" #> [1] \"‚îÇ   ‚îú‚îÄ‚îÄ Compute NA percentage                     \" #> [1] \"‚îÇ   ‚îî‚îÄ‚îÄ Cleaning NA percentage info               \" #> [1] \"‚îî‚îÄ‚îÄ Last cleaning and formating for output        \" #> [1] \"    ‚îú‚îÄ‚îÄ Rename column                             \" #> [1] \"    ‚îî‚îÄ‚îÄ Return data                               \" #> # A tibble: 1 √ó 2 #>   id      `VCN10-5` #>   <chr>       <dbl> #> 1 serie 1    13495. res$dataEX #> $`VCN10-5` #> # A tibble: 1 √ó 2 #>   id      `VCN10-5` #>   <chr>       <dbl> #> 1 serie 1    13495. #>"},{"path":"https://louis-heraut.github.io/CARD/reference/CARD_list_all.html","id":null,"dir":"Reference","previous_headings":"","what":"CARD_list_all ‚Äî CARD_list_all","title":"CARD_list_all ‚Äî CARD_list_all","text":"List CARD parametrization files tibble get metadata aggregation variables available.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/CARD_list_all.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CARD_list_all ‚Äî CARD_list_all","text":"","code":"CARD_list_all(include_experimental = FALSE)"},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/CARD_list_all.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"CARD_list_all ‚Äî CARD_list_all","text":"","code":"# Get all the available variables metaEX_all = CARD_list_all() # And why note filter it by topic dplyr::filter(metaEX_all, grepl(\"Low Flow\", topic_en)) #> # A tibble: 144 √ó 23 #>    CARD_name                variable_en unit_en name_en description_en method_en #>    <chr>                    <chr>       <chr>   <chr>   <chr>          <chr>     #>  1 delta{startLF}_summer_H1 delta{star‚Ä¶ day     Averag‚Ä¶ In summer, da‚Ä¶ \"1. no t‚Ä¶ #>  2 delta{startLF}_summer_H2 delta{star‚Ä¶ day     Averag‚Ä¶ In summer, da‚Ä¶ \"1. no t‚Ä¶ #>  3 delta{startLF}_summer_H3 delta{star‚Ä¶ day     Averag‚Ä¶ In summer, da‚Ä¶ \"1. no t‚Ä¶ #>  4 delta{centerLF}_summer_‚Ä¶ delta{cent‚Ä¶ day     Averag‚Ä¶ In summer, da‚Ä¶ \"1. no t‚Ä¶ #>  5 delta{centerLF}_summer_‚Ä¶ delta{cent‚Ä¶ day     Averag‚Ä¶ In summer, da‚Ä¶ \"1. no t‚Ä¶ #>  6 delta{centerLF}_summer_‚Ä¶ delta{cent‚Ä¶ day     Averag‚Ä¶ In summer, da‚Ä¶ \"1. no t‚Ä¶ #>  7 delta{endLF}_summer_H1   delta{endL‚Ä¶ day     Averag‚Ä¶ In summer, da‚Ä¶ \"1. no t‚Ä¶ #>  8 delta{endLF}_summer_H2   delta{endL‚Ä¶ day     Averag‚Ä¶ In summer, da‚Ä¶ \"1. no t‚Ä¶ #>  9 delta{endLF}_summer_H3   delta{endL‚Ä¶ day     Averag‚Ä¶ In summer, da‚Ä¶ \"1. no t‚Ä¶ #> 10 delta{dtLF}_summer_H1    delta{dtLF‚Ä¶ day     Averag‚Ä¶ In summer, du‚Ä¶ \"1. no t‚Ä¶ #> # ‚Ñπ 134 more rows #> # ‚Ñπ 17 more variables: sampling_period_en <chr>, topic_en <chr>, #> #   variable_fr <chr>, unit_fr <chr>, name_fr <chr>, description_fr <chr>, #> #   method_fr <chr>, sampling_period_fr <chr>, topic_fr <chr>, #> #   is_experimental <lgl>, input_vars <chr>, source <chr>, #> #   preferred_sampling_period <chr>, is_date <lgl>, to_normalise <lgl>, #> #   palette <chr>, script_path <chr>"},{"path":"https://louis-heraut.github.io/CARD/reference/CARD_management.html","id":null,"dir":"Reference","previous_headings":"","what":"CARD_management ‚Äî CARD_management","title":"CARD_management ‚Äî CARD_management","text":"Manage different sets variables extract. CARD advanced users, function manages CARD directory structure performing automatic file operations get CARD parameterization files wanted directory order custom create use second step CARD_extraction(). want submit request new CARD see GitHub repohttps://github.com/super-lou/CARD.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/CARD_management.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CARD_management ‚Äî CARD_management","text":"","code":"CARD_management(   CARD_name = c(\"QA\", \"QJXA\"),   CARD_path = \"./WIP\",   add_id = TRUE,   overwrite = FALSE,   verbose = FALSE )"},{"path":"https://louis-heraut.github.io/CARD/reference/CARD_management.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"CARD_management ‚Äî CARD_management","text":"CARD_name vector character strings specify variables want extract. See CARD_list_all() get variable names. default, c(\"QA\", \"QJXA\"). NULL, variable extracted, avoid value except extract_only_metadata = TRUE. CARD_path optional character string path search custom CARDs created CARD_management function. default, NULL order get default CARD variable parameters. add_id logical. TRUE, numerical IDs added start copied pasted CARD names maintain input order. Default TRUE. overwrite logical. TRUE, existing CARD files analysis directory overwritten. Default TRUE. verbose logical. intermediate messages printed execution function ? Default FALSE.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/CARD_management.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"CARD_management ‚Äî CARD_management","text":"Selected CARD parameterization files created CARD_path directory.","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/CARD_management.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"CARD_management ‚Äî CARD_management","text":"","code":"# Get the QA and QMNA CARD variables in your local CARD_path directory CARD_management(CARD_name=c(\"QA\", \"QMNA\"),                 CARD_path=\"CARD-WIP\",                 overwrite = TRUE)"},{"path":"https://louis-heraut.github.io/CARD/reference/apply_threshold.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply Threshold to Identify Events ‚Äî apply_threshold","title":"Apply Threshold to Identify Events ‚Äî apply_threshold","text":"Identifies extracts events time series based threshold criteria, options event selection characterization.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/apply_threshold.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply Threshold to Identify Events ‚Äî apply_threshold","text":"","code":"apply_threshold(   X,   lim,   where = \"<=\",   what = \"X\",   select = \"all\",   Date = NULL,   period = NULL )"},{"path":"https://louis-heraut.github.io/CARD/reference/apply_threshold.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply Threshold to Identify Events ‚Äî apply_threshold","text":"X Numeric vector values analyze (typically discharge hydro-meteorological variable) lim Numeric threshold value vector length X String specifying threshold condition: \"<\", \"<=\", \"==\", \">=\", \">\" standard comparisons String specifying return type: \"X\": Values meeting condition \"length\": Duration events (time steps) \"first\"/\"last\": First/last index events function name (e.g., \".max\"): Applied event values select String numeric specifying event selection: \"\": events (default) \"longest\"/\"shortest\": Longest/shortest event Numeric value: Event containing value Date Optional date vector period filtering period Optional vector 2 dates (start/end) period filtering","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/apply_threshold.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply Threshold to Identify Events ‚Äî apply_threshold","text":"Depends parameter: Numeric vector values (\"X\") Integer duration (\"length\") Single index (\"first\"/\"last\") Function application result NA events found","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/apply_threshold.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Apply Threshold to Identify Events ‚Äî apply_threshold","text":"Handles multiple threshold scenarios: vector lim, uses frequent value via rle() period filtering, subsets data analysis event selection, identifies contiguous periods","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/apply_threshold.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply Threshold to Identify Events ‚Äî apply_threshold","text":"","code":"set.seed(1) Q <- rnorm(100, 50, 10) # Simulated discharge  # Get longest drought period (Q <= 45) drought_days <- apply_threshold(Q, 45, where=\"<=\", what=\"length\", select=\"longest\")  # Get first index of all flood events (Q >= 60) flood_starts <- apply_threshold(Q, 60, where=\">=\", what=\"first\")"},{"path":"https://louis-heraut.github.io/CARD/reference/approxExtrap.html","id":null,"dir":"Reference","previous_headings":"","what":"approxExtrap ‚Äî approxExtrap","title":"approxExtrap ‚Äî approxExtrap","text":"Performs linear interpolation using approx() linear extrapolation beyond data range. function particularly useful need estimate values outside range observed data points.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/approxExtrap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"approxExtrap ‚Äî approxExtrap","text":"","code":"approxExtrap(   x,   y,   xout,   method = \"linear\",   n = 50,   rule = 2,   f = 0,   ties = \"ordered\",   na.rm = FALSE )"},{"path":"https://louis-heraut.github.io/CARD/reference/approxExtrap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"approxExtrap ‚Äî approxExtrap","text":"x Either vector x-coordinates points interpolated, list components x y. list provided, y parameter ignored. y Vector y-coordinates points interpolated, corresponding x. xout Vector points evaluate interpolation/extrapolation. method Specifies interpolation method. \"linear\" currently supported. default \"linear\". n xout specified, interpolation done n equally spaced points covering range x. default 50. rule integer (1 2) describing interpolation take place outside interval min(x), max(x). See approx() details. default 2. f method = \"constant\", number 0 1 inclusive, indicating interpolation behave jump discontinuities. See approx() details. default 0. ties Handling tied x values. See approx() details. default \"ordered\". na.rm Logical indicating whether NA values removed interpolation. default FALSE.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/approxExtrap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"approxExtrap ‚Äî approxExtrap","text":"list components: x x-coordinates interpolation performed (input xout) y interpolated/extrapolated y-values corresponding xout","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/approxExtrap.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"approxExtrap ‚Äî approxExtrap","text":"function first performs standard linear interpolation using approx(). points outside range input data, performs linear extrapolation using slope defined first two points (low extrapolation) last two points (high extrapolation). function handles duplicate x-values removing orders data x-values ensure proper interpolation extrapolation.","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/approxExtrap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"approxExtrap ‚Äî approxExtrap","text":"","code":"# Basic interpolation and extrapolation x <- 1:5 y <- c(2, 4, 3, 6, 5) approxExtrap(x, y, xout = c(0, 1, 3.5, 5, 6)) #> $x #> [1] 0.0 1.0 3.5 5.0 6.0 #>  #> $y #> [1] 0.0 2.0 4.5 5.0 4.0 #>   # With NA values (when na.rm = TRUE) x <- c(1, 2, NA, 4, 5) y <- c(2, 4, 5, 6, 5) approxExtrap(x, y, xout = 1:6, na.rm = TRUE) #> $x #> [1] 1 2 3 4 5 6 #>  #> $y #> [1] 2 4 5 6 5 4 #>"},{"path":"https://louis-heraut.github.io/CARD/reference/circular_divided.html","id":null,"dir":"Reference","previous_headings":"","what":"circular_divided ‚Äî circular_divided","title":"circular_divided ‚Äî circular_divided","text":"description","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/circular_divided.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"circular_divided ‚Äî circular_divided","text":"","code":"circular_divided(X, Y, periodicity)"},{"path":"https://louis-heraut.github.io/CARD/reference/circular_divided.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"circular_divided ‚Äî circular_divided","text":"Q discharge","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/circular_median.html","id":null,"dir":"Reference","previous_headings":"","what":"circular_median ‚Äî circular_median","title":"circular_median ‚Äî circular_median","text":"description","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/circular_median.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"circular_median ‚Äî circular_median","text":"","code":"circular_median(X, periodicity, na.rm = TRUE)"},{"path":"https://louis-heraut.github.io/CARD/reference/circular_median.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"circular_median ‚Äî circular_median","text":"Q discharge","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/circular_minus.html","id":null,"dir":"Reference","previous_headings":"","what":"circular_minus ‚Äî circular_minus","title":"circular_minus ‚Äî circular_minus","text":"description","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/circular_minus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"circular_minus ‚Äî circular_minus","text":"","code":"circular_minus(X, Y, periodicity)"},{"path":"https://louis-heraut.github.io/CARD/reference/circular_minus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"circular_minus ‚Äî circular_minus","text":"Q discharge","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/compute_Biais.html","id":null,"dir":"Reference","previous_headings":"","what":"Biais ‚Äî compute_Biais","title":"Biais ‚Äî compute_Biais","text":"Computes bias (unitless) simulated observed data","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_Biais.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Biais ‚Äî compute_Biais","text":"","code":"compute_Biais(obs, sim, na.rm = TRUE, sim_minus_obs = TRUE)"},{"path":"https://louis-heraut.github.io/CARD/reference/compute_Biais.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Biais ‚Äî compute_Biais","text":"obs Observed streamflow vector sim Simulated streamflow vector na.rm missing values omited ? sim_minus_obs: sim - obs ? (way around)","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_FDC.html","id":null,"dir":"Reference","previous_headings":"","what":"fdc_values ‚Äî compute_FDC","title":"fdc_values ‚Äî compute_FDC","text":"Given vector streamflow values, computes data.frame two columns : 'p' column containing probability exceedance 'Q' column containing corresponding streamflow values. Two methods can used : simply sorting data (recommended) using quantile function.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_FDC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"fdc_values ‚Äî compute_FDC","text":"","code":"compute_FDC(Q, n = 1000, sort = FALSE, isNormLaw = FALSE, na.rm = TRUE)"},{"path":"https://louis-heraut.github.io/CARD/reference/compute_FDC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"fdc_values ‚Äî compute_FDC","text":"Q Streamflow vector n number rows resulting data.frame (smaller length 'Q'. sort logical. sort function used instead quantile function ? na.rm logical. missing values ignored ? (must TRUE quantile function used !)","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_FDC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"fdc_values ‚Äî compute_FDC","text":"res","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_FDC_Q.html","id":null,"dir":"Reference","previous_headings":"","what":"compute_FDC_Q ‚Äî compute_FDC_Q","title":"compute_FDC_Q ‚Äî compute_FDC_Q","text":"description","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_FDC_Q.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"compute_FDC_Q ‚Äî compute_FDC_Q","text":"","code":"compute_FDC_Q(Q, n = 1000, sort = FALSE, isNormLaw = FALSE, na.rm = TRUE)"},{"path":"https://louis-heraut.github.io/CARD/reference/compute_FDC_Q.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"compute_FDC_Q ‚Äî compute_FDC_Q","text":"Q discharge","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/compute_FDC_p.html","id":null,"dir":"Reference","previous_headings":"","what":"compute_FDC_p ‚Äî compute_FDC_p","title":"compute_FDC_p ‚Äî compute_FDC_p","text":"description","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_FDC_p.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"compute_FDC_p ‚Äî compute_FDC_p","text":"","code":"compute_FDC_p(n = 1000, sort = FALSE, isNormLaw = FALSE, na.rm = TRUE)"},{"path":"https://louis-heraut.github.io/CARD/reference/compute_FDC_p.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"compute_FDC_p ‚Äî compute_FDC_p","text":"Q discharge","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/compute_GumbelLaw.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Quantile from Gumbel Law ‚Äî compute_GumbelLaw","title":"Compute Quantile from Gumbel Law ‚Äî compute_GumbelLaw","text":"Calculates discharge value (quantile) associated given return period using Gumbel distribution parameters.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_GumbelLaw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Quantile from Gumbel Law ‚Äî compute_GumbelLaw","text":"","code":"compute_GumbelLaw(a, b, returnPeriod)"},{"path":"https://louis-heraut.github.io/CARD/reference/compute_GumbelLaw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Quantile from Gumbel Law ‚Äî compute_GumbelLaw","text":"Numeric value Gumbel distribution location parameter. b Numeric value Gumbel distribution scale parameter. returnPeriod Numeric value return period (years consistent time unit).","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_GumbelLaw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Quantile from Gumbel Law ‚Äî compute_GumbelLaw","text":"Numeric value representing estimated discharge given return period.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_GumbelParams.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Gumbel Distribution Parameters ‚Äî compute_GumbelParams","title":"Estimate Gumbel Distribution Parameters ‚Äî compute_GumbelParams","text":"Computes location () scale (b) parameters Gumbel distribution based numeric vector annual maximum flows.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_GumbelParams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Gumbel Distribution Parameters ‚Äî compute_GumbelParams","text":"","code":"compute_GumbelParams(X)"},{"path":"https://louis-heraut.github.io/CARD/reference/compute_GumbelParams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Gumbel Distribution Parameters ‚Äî compute_GumbelParams","text":"X Numeric vector representing maximum flows (e.g., annual daily maxima).","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_GumbelParams.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Gumbel Distribution Parameters ‚Äî compute_GumbelParams","text":"list location parameter b scale parameter).","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_KGE.html","id":null,"dir":"Reference","previous_headings":"","what":"KGE ‚Äî compute_KGE","title":"KGE ‚Äî compute_KGE","text":"Computes Kling-Gupta efficiency coefficient. function largely inspired similar function HydroGOF package. , simplified version provided checks inputs little formatting speed .","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_KGE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"KGE ‚Äî compute_KGE","text":"","code":"compute_KGE(obs, sim, na.rm = TRUE, method = 1)"},{"path":"https://louis-heraut.github.io/CARD/reference/compute_KGE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"KGE ‚Äî compute_KGE","text":"obs Observed streamflow vector sim Simulated streamflow vector na.rm missing values omited? method Two methods implemented (see hydroGOF::KGE): '1' Gupta et al. (2009) '2' Kling et al. (2012)","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_KGE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"KGE ‚Äî compute_KGE","text":"KGE","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_KGEracine.html","id":null,"dir":"Reference","previous_headings":"","what":"KGEracine ‚Äî compute_KGEracine","title":"KGEracine ‚Äî compute_KGEracine","text":"Computes ","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_KGEracine.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"KGEracine ‚Äî compute_KGEracine","text":"","code":"compute_KGEracine(obs, sim, na.rm = TRUE)"},{"path":"https://louis-heraut.github.io/CARD/reference/compute_KGEracine.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"KGEracine ‚Äî compute_KGEracine","text":"obs Observed streamflow vector sim Simulated streamflow vector na.rm missing values omited ?","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_KGEracine.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"KGEracine ‚Äî compute_KGEracine","text":"KGEracine according parametrization","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_LogNormal.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Return Value using Log-Normal Distribution ‚Äî compute_LogNormal","title":"Estimate Return Value using Log-Normal Distribution ‚Äî compute_LogNormal","text":"Calculation value according return period according Galton distribution (log-normal)","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_LogNormal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Return Value using Log-Normal Distribution ‚Äî compute_LogNormal","text":"","code":"compute_LogNormal(X, returnPeriod)"},{"path":"https://louis-heraut.github.io/CARD/reference/compute_LogNormal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Return Value using Log-Normal Distribution ‚Äî compute_LogNormal","text":"X Numeric vector annual data (e.g., minimum maximum discharge). returnPeriod Numeric value return period years.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_LogNormal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Return Value using Log-Normal Distribution ‚Äî compute_LogNormal","text":"Numeric value return period according Galton distribution.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_NSE.html","id":null,"dir":"Reference","previous_headings":"","what":"NSE ‚Äî compute_NSE","title":"NSE ‚Äî compute_NSE","text":"Computes Nash-Sutcliffe efficiency coefficient","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_NSE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"NSE ‚Äî compute_NSE","text":"","code":"compute_NSE(obs, sim, na.rm = TRUE)"},{"path":"https://louis-heraut.github.io/CARD/reference/compute_NSE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"NSE ‚Äî compute_NSE","text":"obs Observed streamflow vector sim Simulated streamflow vector na.rm missing values omited ?","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_NSE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"NSE ‚Äî compute_NSE","text":"1 - sum((sim-obs)^2)/sum((obs-mean(obs))^2)","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_NSEi.html","id":null,"dir":"Reference","previous_headings":"","what":"NSEi ‚Äî compute_NSEi","title":"NSEi ‚Äî compute_NSEi","text":"Computes Nash-Sutcliffe efficiency coefficient ","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_NSEi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"NSEi ‚Äî compute_NSEi","text":"","code":"compute_NSEi(obs, sim, na.rm = TRUE)"},{"path":"https://louis-heraut.github.io/CARD/reference/compute_NSEi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"NSEi ‚Äî compute_NSEi","text":"obs Observed streamflow vector sim Simulated streamflow vector na.rm missing values omited ?","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_NSEi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"NSEi ‚Äî compute_NSEi","text":"NSEi according parametrization","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_NSElog.html","id":null,"dir":"Reference","previous_headings":"","what":"NSElog ‚Äî compute_NSElog","title":"NSElog ‚Äî compute_NSElog","text":"Computes Nash-Sutcliffe efficiency coefficient log transformed streamflow values using 'hsaLog' function 'NSE' function","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_NSElog.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"NSElog ‚Äî compute_NSElog","text":"","code":"compute_NSElog(obs, sim, na.rm = TRUE, log_method = \"inf.na\")"},{"path":"https://louis-heraut.github.io/CARD/reference/compute_NSElog.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"NSElog ‚Äî compute_NSElog","text":"obs Observed streamflow vector sim Simulated streamflow vector na.rm missing values omited ? log_method See 'hsaLog'","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_NSElog.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"NSElog ‚Äî compute_NSElog","text":"NSElog according parametrization","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_NSEracine.html","id":null,"dir":"Reference","previous_headings":"","what":"NSEracine ‚Äî compute_NSEracine","title":"NSEracine ‚Äî compute_NSEracine","text":"Computes Nash-Sutcliffe efficiency coefficient ","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_NSEracine.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"NSEracine ‚Äî compute_NSEracine","text":"","code":"compute_NSEracine(obs, sim, na.rm = TRUE)"},{"path":"https://louis-heraut.github.io/CARD/reference/compute_NSEracine.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"NSEracine ‚Äî compute_NSEracine","text":"obs Observed streamflow vector sim Simulated streamflow vector na.rm missing values omited ?","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_NSEracine.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"NSEracine ‚Äî compute_NSEracine","text":"NSEracine according parametrization","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_Qp.html","id":null,"dir":"Reference","previous_headings":"","what":"compute_Qp ‚Äî compute_Qp","title":"compute_Qp ‚Äî compute_Qp","text":"description","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_Qp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"compute_Qp ‚Äî compute_Qp","text":"","code":"compute_Qp(Q, p)"},{"path":"https://louis-heraut.github.io/CARD/reference/compute_Qp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"compute_Qp ‚Äî compute_Qp","text":"Q discharge","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/compute_R2.html","id":null,"dir":"Reference","previous_headings":"","what":"R2 ‚Äî compute_R2","title":"R2 ‚Äî compute_R2","text":"Computes coefficient determination using cor() function simulated observed data","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_R2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"R2 ‚Äî compute_R2","text":"","code":"compute_R2(   obs,   sim,   na.rm = TRUE,   method = c(\"pearson\", \"kendall\", \"spearman\") )"},{"path":"https://louis-heraut.github.io/CARD/reference/compute_R2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"R2 ‚Äî compute_R2","text":"obs Observed streamflow vector sim Simulated streamflow vector na.rm missing values omited ? method method use cor() function","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_R2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"R2 ‚Äî compute_R2","text":"R2","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_RAT_X.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Robustness Assessment Test (RAT) Indicator ‚Äî compute_RAT_X","title":"Compute Robustness Assessment Test (RAT) Indicator ‚Äî compute_RAT_X","text":"Evaluates robustness hydrological model performance metric (e.g., Bias) respect explanatory variable (e.g., discharge characteristics), using Spearman correlation test. function returns Boolean indicating whether significant correlation exists, implying potential lack robustness. Based RAT (Robustness Assessment Test) methodology introduced Nicolle et al. (2020), function tests whether variability model performance criterion can explained explanatory variable, suggesting lack robustness .","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_RAT_X.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Robustness Assessment Test (RAT) Indicator ‚Äî compute_RAT_X","text":"","code":"compute_RAT_X(Bias, X, thresh = 0.05)"},{"path":"https://louis-heraut.github.io/CARD/reference/compute_RAT_X.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Robustness Assessment Test (RAT) Indicator ‚Äî compute_RAT_X","text":"Bias Numeric vector model performance scores (e.g., Bias) across sub-basins, time periods, experiments. X Numeric vector explanatory variable (e.g., flow regime characteristic) length Bias. thresh Numeric threshold p-value Spearman correlation test. Default 0.05 (5% significance level).","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_RAT_X.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Robustness Assessment Test (RAT) Indicator ‚Äî compute_RAT_X","text":"Logical. Returns TRUE correlation significant (.e., p-value < thresh), indicating lack robustness; FALSE otherwise.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_RAT_X.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute Robustness Assessment Test (RAT) Indicator ‚Äî compute_RAT_X","text":"Nicolle, P., Andr√©assian, V., Royer-Gaspard, P., Perrin, C., Thirel, G., Coron, L., & Santos, L. (2020). RAT ‚Äì robustness assessment test calibrated uncalibrated hydrological models. Hydrological Sciences Journal, 65(6), 959‚Äì972. https://doi.org/10.1080/02626667.2020.1737689","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_Rc.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Runoff Coefficient ‚Äî compute_Rc","title":"Compute Runoff Coefficient ‚Äî compute_Rc","text":"Calculates runoff coefficient (Rc) ratio total streamflow volume total precipitation volume specified period, typically hydrological year.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_Rc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Runoff Coefficient ‚Äî compute_Rc","text":"","code":"compute_Rc(Q, R, na.rm = TRUE)"},{"path":"https://louis-heraut.github.io/CARD/reference/compute_Rc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Runoff Coefficient ‚Äî compute_Rc","text":"Q Numeric vector streamflow/discharge values L¬≥/T R Numeric vector precipitation values L/T na.rm Logical indicating whether ignore missing values (NA) calculations. Default TRUE.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_Rc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Runoff Coefficient ‚Äî compute_Rc","text":"numeric value representing runoff coefficient (dimensionless): 0 indicates runoff 1 indicates precipitation becomes runoff Values >1 suggest groundwater contributions measurement errors","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_Rc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute Runoff Coefficient ‚Äî compute_Rc","text":"runoff coefficient calculated : $$Rc = \\frac{\\sum Q}{\\sum R}$$ Important notes: Input vectors must cover time period computed complete hydrological years unit conversion performed - ensure consistent units Negative values produce invalid results","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_Rc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Runoff Coefficient ‚Äî compute_Rc","text":"","code":"# Example for a hydrological year Q <- c(10, 12, 15, 20, 18, 16, 14, 12, 10, 9, 8, 7)  # Streamflow (mm/month) P <- c(20, 25, 30, 35, 40, 45, 40, 35, 30, 25, 20, 15) # Precipitation (mm/month)  rc <- compute_Rc(Q, P) print(paste(\"Runoff coefficient:\", round(rc, 3))) #> [1] \"Runoff coefficient: 0.419\""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_STD.html","id":null,"dir":"Reference","previous_headings":"","what":"compute_STD ‚Äî compute_STD","title":"compute_STD ‚Äî compute_STD","text":"description","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_STD.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"compute_STD ‚Äî compute_STD","text":"","code":"compute_STD(obs, sim, na.rm = TRUE)"},{"path":"https://louis-heraut.github.io/CARD/reference/compute_STD.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"compute_STD ‚Äî compute_STD","text":"Q discharge","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/compute_VolDef.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Volume Deficit Below Threshold ‚Äî compute_VolDef","title":"Compute Volume Deficit Below Threshold ‚Äî compute_VolDef","text":"Calculates cumulative volume deficit specified threshold longest continuous deficit period.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_VolDef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Volume Deficit Below Threshold ‚Äî compute_VolDef","text":"","code":"compute_VolDef(Q, upLim, select_longest = TRUE)"},{"path":"https://louis-heraut.github.io/CARD/reference/compute_VolDef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Volume Deficit Below Threshold ‚Äî compute_VolDef","text":"Q Numeric vector streamflow values m¬≥/s upLim Numeric upper threshold deficit calculation select_longest Logical indicating whether use longest deficit period (TRUE) periods (FALSE). Currently TRUE implemented.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_VolDef.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Volume Deficit Below Threshold ‚Äî compute_VolDef","text":"Numeric value volume deficit cubic hectometers (hm¬≥)","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_VolDef.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute Volume Deficit Below Threshold ‚Äî compute_VolDef","text":"Computes: $$VolDef = \\frac{\\sum (Q_{deficit}) \\times 86400}{10^6}$$ : $Q_deficit$ flows threshold longest event 86400 converts seconds days 10^6 converts m¬≥ hm¬≥","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/compute_VolDef.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Volume Deficit Below Threshold ‚Äî compute_VolDef","text":"","code":"Q <- c(45, 42, 39, 38, 40, 50, 48, 37, 36, 35, 40) # Calculate volume deficit below 40 m¬≥/s vol_def <- compute_VolDef(Q, upLim=40) print(paste(\"Volume deficit:\", round(vol_def, 2), \"hm¬≥\")) #> [1] \"Volume deficit: 12.79 hm¬≥\""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_VolSnowmelt.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Total Snowmelt Volume ‚Äî compute_VolSnowmelt","title":"Compute Total Snowmelt Volume ‚Äî compute_VolSnowmelt","text":"Calculates total snowmelt volume (hm¬≥) baseflow separation, assuming baseflow represents snowmelt contributions streamflow.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_VolSnowmelt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Total Snowmelt Volume ‚Äî compute_VolSnowmelt","text":"","code":"compute_VolSnowmelt(Q, d = 5, w = 0.9, a = 0.925, passes = 3, method = \"Wal\")"},{"path":"https://louis-heraut.github.io/CARD/reference/compute_VolSnowmelt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Total Snowmelt Volume ‚Äî compute_VolSnowmelt","text":"Numeric value total snowmelt volume cubic hectometers (hm¬≥).","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_VolSnowmelt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute Total Snowmelt Volume ‚Äî compute_VolSnowmelt","text":"Computes: $$VolSnowmelt = \\frac{\\sum BF \\times 86400}{10^6}$$ : BF baseflow BFS 86400 converts seconds days 10^6 converts m¬≥ hm¬≥","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/compute_VolSnowmelt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Total Snowmelt Volume ‚Äî compute_VolSnowmelt","text":"","code":"Q <- c(10,15,20,18,12,8,5,7,9,12) # Sample streamflow (m¬≥/s) compute_VolSnowmelt(Q) # Returns volume in hm¬≥ #> [1] 0"},{"path":"https://louis-heraut.github.io/CARD/reference/compute_dtRec.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Characteristic Recovery Times from Flow Time Series ‚Äî compute_dtRec","title":"Compute Characteristic Recovery Times from Flow Time Series ‚Äî compute_dtRec","text":"Applies smoothing inflection point detection estimate recovery durations (Tau) hydrological peaks valleys discharge time series.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_dtRec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Characteristic Recovery Times from Flow Time Series ‚Äî compute_dtRec","text":"","code":"compute_dtRec(Q)"},{"path":"https://louis-heraut.github.io/CARD/reference/compute_dtRec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Characteristic Recovery Times from Flow Time Series ‚Äî compute_dtRec","text":"Q Numeric vector discharge values.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_dtRec.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Characteristic Recovery Times from Flow Time Series ‚Äî compute_dtRec","text":"numeric vector recovery times (Tau) peak valley periods, filtered quantile thresholds.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_elasticity.html","id":null,"dir":"Reference","previous_headings":"","what":"Elasticity ‚Äî compute_elasticity","title":"Elasticity ‚Äî compute_elasticity","text":"quote Yushiou Tsai (2016) : \"used elasticity assess sensitivity mean drought flows changes climate, land use land cover (LULC), water use across broad region. ... Sankarasubramanian et al. (2001) suggested () bivariate empirical estimator precipitation elasticity mean flow\". last estimator use function.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_elasticity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Elasticity ‚Äî compute_elasticity","text":"","code":"compute_elasticity(Q, X)"},{"path":"https://louis-heraut.github.io/CARD/reference/compute_elasticity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Elasticity ‚Äî compute_elasticity","text":"Q discharge X variable","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_elasticity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Elasticity ‚Äî compute_elasticity","text":"Elasticity given : eps_X = median((Q-Qmean)/(X-Xmean) * Xmean/Qmean)","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_fAp.html","id":null,"dir":"Reference","previous_headings":"","what":"compute_fAp ‚Äî compute_fAp","title":"compute_fAp ‚Äî compute_fAp","text":"description","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_fAp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"compute_fAp ‚Äî compute_fAp","text":"","code":"compute_fAp(Q, lowLim)"},{"path":"https://louis-heraut.github.io/CARD/reference/compute_fAp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"compute_fAp ‚Äî compute_fAp","text":"Q discharge","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/compute_hsaLog.html","id":null,"dir":"Reference","previous_headings":"","what":"hsaLog ‚Äî compute_hsaLog","title":"hsaLog ‚Äî compute_hsaLog","text":"Computes log transformed value streamflow using either approach proposed Pushpalatha et al. (2012), adding given value streamflow values simply setting NA non finite value resulting application log().","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_hsaLog.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"hsaLog ‚Äî compute_hsaLog","text":"","code":"compute_hsaLog(x, method = \"inf.na\")"},{"path":"https://louis-heraut.github.io/CARD/reference/compute_hsaLog.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"hsaLog ‚Äî compute_hsaLog","text":"x streamflow vector method method use : 'Pushpalatha2012', numeric value (added 'x') 'inf.na'","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_hsaLog.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"hsaLog ‚Äî compute_hsaLog","text":"log(x) according parametrization","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_median_dtRec.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Median Recovery Time ‚Äî compute_median_dtRec","title":"Compute Median Recovery Time ‚Äî compute_median_dtRec","text":"Calculates median recovery times (Tau) estimated compute_dtRec, optionally removing NA values.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_median_dtRec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Median Recovery Time ‚Äî compute_median_dtRec","text":"","code":"compute_median_dtRec(Q, na.rm = TRUE)"},{"path":"https://louis-heraut.github.io/CARD/reference/compute_median_dtRec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Median Recovery Time ‚Äî compute_median_dtRec","text":"Q Numeric vector discharge values. na.rm Logical indicating whether remove NA values computing median.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_median_dtRec.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Median Recovery Time ‚Äî compute_median_dtRec","text":"single numeric value representing median recovery time.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_tSnowmelt.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Snowmelt Period Duration ‚Äî compute_tSnowmelt","title":"Compute Snowmelt Period Duration ‚Äî compute_tSnowmelt","text":"Calculates duration two percentage points snowmelt progression.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_tSnowmelt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Snowmelt Period Duration ‚Äî compute_tSnowmelt","text":"","code":"compute_tSnowmelt(   Q,   p1,   p2,   d = 5,   w = 0.9,   a = 0.925,   passes = 3,   method = \"Wal\" )"},{"path":"https://louis-heraut.github.io/CARD/reference/compute_tSnowmelt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Snowmelt Period Duration ‚Äî compute_tSnowmelt","text":"p1, p2 Numerics (0-1) specifying start end percentages","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_tSnowmelt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Snowmelt Period Duration ‚Äî compute_tSnowmelt","text":"Integer duration (time steps) p1 p2 snowmelt percentages.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_tSnowmelt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute Snowmelt Period Duration ‚Äî compute_tSnowmelt","text":"Typical usage: p1=0.05 (start melt period) p2=0.95 (end melt period) Returns number days events","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/compute_tSnowmelt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Snowmelt Period Duration ‚Äî compute_tSnowmelt","text":"","code":"Q <- c(rep(5,30), seq(5,25,length.out=30), rep(25,30), seq(25,5,length.out=30)) # Calculate duration between 10% and 90% snowmelt: compute_tSnowmelt(Q, p1=0.1, p2=0.9) #> [1] 70"},{"path":"https://louis-heraut.github.io/CARD/reference/compute_tVolSnowmelt.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Snowmelt Progress Time ‚Äî compute_tVolSnowmelt","title":"Compute Snowmelt Progress Time ‚Äî compute_tVolSnowmelt","text":"Finds time index certain percentage total snowmelt volume reached.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_tVolSnowmelt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Snowmelt Progress Time ‚Äî compute_tVolSnowmelt","text":"","code":"compute_tVolSnowmelt(   Q,   p,   d = 5,   w = 0.9,   a = 0.925,   passes = 3,   method = \"Wal\" )"},{"path":"https://louis-heraut.github.io/CARD/reference/compute_tVolSnowmelt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Snowmelt Progress Time ‚Äî compute_tVolSnowmelt","text":"p Numeric (0-1) specifying target progress percentage","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_tVolSnowmelt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Snowmelt Progress Time ‚Äî compute_tVolSnowmelt","text":"Integer index cumulative snowmelt reaches p% total volume.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/compute_tVolSnowmelt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute Snowmelt Progress Time ‚Äî compute_tVolSnowmelt","text":"Computes: Cumulative sum baseflow (snowmelt) Normalizes 0-1 range Finds closest time index target percentage p","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/compute_tVolSnowmelt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Snowmelt Progress Time ‚Äî compute_tVolSnowmelt","text":"","code":"Q <- c(10,15,20,18,12,8,5,7,9,12) # Find when 50% of snowmelt has occurred: compute_tVolSnowmelt(Q, p=0.5)  #> [1] NA"},{"path":"https://louis-heraut.github.io/CARD/reference/dBFS.html","id":null,"dir":"Reference","previous_headings":"","what":"dBFS ‚Äî dBFS","title":"dBFS ‚Äî dBFS","text":"Calculates difference total streamflow baseflow (Q - baseflow) using BFS. typically represents quickflow (surface runoff + interflow), interpretation depends baseflow separation method used.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/dBFS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"dBFS ‚Äî dBFS","text":"","code":"dBFS(Q, d = 5, w = 0.9, a = 0.925, passes = 3, method = \"Wal\")"},{"path":"https://louis-heraut.github.io/CARD/reference/dBFS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"dBFS ‚Äî dBFS","text":"Q Numeric vector discharge (streamflow) values. Missing values (NA) allowed. d Integer specifying window size (days) identifying minima Wallingford method. Default 5. w Numeric weighting factor (0-1) used Wallingford method identify turning points. Default 0.9. Numeric filter parameter (0-1) Lyne & Hollick method, higher values result smoother baseflow. Default 0.925. passes Integer specifying number forward/backward passes Lyne & Hollick method. Default 3 (recommended optimal results). method Character specifying separation method: \"Wal\" Wallingford \"LH\" Lyne & Hollick. Default \"Wal\".","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/dBFS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"dBFS ‚Äî dBFS","text":"numeric vector (Q - baseflow) values. interpretation depends method: method = \"Wal\": Represents quickflow (surface runoff + interflow) method = \"LH\": Represents filtered quickflow component Returns NA input contains NA values.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/dBFS.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"dBFS ‚Äî dBFS","text":"function computes difference total streamflow (Q) baseflow estimated BFS: $$quickflow = Q - BFS(Q, ...)$$ Note : result direct runoff hydrological sense components depend separation method's assumptions Negative values possible due separation artifacts","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/dBFS.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"dBFS ‚Äî dBFS","text":"","code":"# Calculate quickflow component using Wallingford method Q <- c(10, 12, 15, 20, 18, 16, 14, 12, 10, 9) quickflow <- dBFS(Q, method = \"Wal\")"},{"path":"https://louis-heraut.github.io/CARD/reference/divided.html","id":null,"dir":"Reference","previous_headings":"","what":"divided ‚Äî divided","title":"divided ‚Äî divided","text":"description","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/divided.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"divided ‚Äî divided","text":"","code":"divided(a, b, first = FALSE)"},{"path":"https://louis-heraut.github.io/CARD/reference/divided.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"divided ‚Äî divided","text":"Q discharge","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/fdc_slope.html","id":null,"dir":"Reference","previous_headings":"","what":"fdc_slope ‚Äî fdc_slope","title":"fdc_slope ‚Äî fdc_slope","text":"Compute mid-segment flow duration curve slope","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/fdc_slope.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"fdc_slope ‚Äî fdc_slope","text":"","code":"fdc_slope(Q, p = c(0.33, 0.66))"},{"path":"https://louis-heraut.github.io/CARD/reference/fdc_slope.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"fdc_slope ‚Äî fdc_slope","text":"Q Streamflow vector p length 2 numeric vector containing exceedance probability define mid-segment","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/fdc_slope.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"fdc_slope ‚Äî fdc_slope","text":"Mid-segment low duration curve slope","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/get_BFI.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Baseflow Index ‚Äî get_BFI","title":"Compute Baseflow Index ‚Äî get_BFI","text":"Calculates Baseflow Index (BFI), defined ratio total baseflow volume total streamflow volume given period. BFI represents proportion streamflow comes baseflow (groundwater contributions).","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/get_BFI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Baseflow Index ‚Äî get_BFI","text":"","code":"get_BFI(Q, BF, na.rm = TRUE)"},{"path":"https://louis-heraut.github.io/CARD/reference/get_BFI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Baseflow Index ‚Äî get_BFI","text":"Q Numeric vector streamflow/discharge values L¬≥/T BF Numeric vector baseflow values L¬≥/T, typically obtained baseflow separation method (must length Q) na.rm Logical indicating whether ignore missing values (NA) calculations. Default TRUE.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/get_BFI.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Baseflow Index ‚Äî get_BFI","text":"numeric value 0 1 representing baseflow index: 0 indicates streamflow quickflow (surface runoff) 1 indicates streamflow baseflow","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/get_BFI.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute Baseflow Index ‚Äî get_BFI","text":"Baseflow Index calculated : $$BFI = \\frac{\\sum BF}{\\sum Q}$$ Important notes: function assumes vectors cover time period automatic alignment time series performed Negative values either vector produce invalid results Results meaningful using consistent units Q BF","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/get_BFI.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Baseflow Index ‚Äî get_BFI","text":"","code":"# Example using synthetic data Q <- c(10, 12, 15, 20, 18, 16, 14, 12, 10, 9)  # Streamflow BF <- c(8, 8, 9, 9, 9, 8, 8, 8, 7, 7)          # Baseflow  # Calculate BFI bfi <- get_BFI(Q, BF) print(paste(\"Baseflow Index:\", round(bfi, 3))) #> [1] \"Baseflow Index: 0.596\"  # With missing values Q[3] <- NA get_BFI(Q, BF)               # Returns NA #> [1] 0.6694215 get_BFI(Q, BF, na.rm=TRUE)   # Ignores NA #> [1] 0.6694215"},{"path":"https://louis-heraut.github.io/CARD/reference/get_BFM.html","id":null,"dir":"Reference","previous_headings":"","what":"Baseflow Magnitude ‚Äî get_BFM","title":"Baseflow Magnitude ‚Äî get_BFM","text":"Calculates relative difference maximum minimum values baseflow time series, representing seasonal variability baseflow contributions.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/get_BFM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Baseflow Magnitude ‚Äî get_BFM","text":"","code":"get_BFM(BFA)"},{"path":"https://louis-heraut.github.io/CARD/reference/get_BFM.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Baseflow Magnitude ‚Äî get_BFM","text":"BFA Numeric vector inter-annual daily average baseflow values L¬≥/T","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/get_BFM.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Baseflow Magnitude ‚Äî get_BFM","text":"numeric value 0 1 representing baseflow variability: 0 indicates seasonal variability (constant baseflow) 1 indicates extreme variability (minimum baseflow approaches zero)","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/get_BFM.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Baseflow Magnitude ‚Äî get_BFM","text":"Baseflow Regime Magnitude calculated : $$BFM = \\frac{BFA_{max} - BFA_{min}}{BFA_{max}}$$ : \\(BFA_{max}\\) maximum baseflow series \\(BFA_{min}\\) minimum baseflow series Key characteristics: Returns value 0 (variability) 1 (maximum variability) Handles missing values (NA) automatically smoothing applied input series Particularly useful comparing seasonal baseflow patterns catchments","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/get_BFM.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Baseflow Magnitude ‚Äî get_BFM","text":"","code":"# Example with synthetic baseflow data (annual cycle) baseflow <- c(rep(5,90), rep(8,90), rep(12,90), rep(7,95)) # Seasonal pattern result <- get_BFM(baseflow)  print(paste(\"Baseflow variability:\", round(result$magnitude, 2))) #> Error in result$magnitude: $ operator is invalid for atomic vectors print(paste(\"Maximum baseflow:\", round(result$max, 2))) #> Error in result$max: $ operator is invalid for atomic vectors print(paste(\"Minimum baseflow:\", round(result$min, 2))) #> Error in result$min: $ operator is invalid for atomic vectors  # Example with real data (would need actual baseflow series) # data(streamflow) # bf <- BFS(streamflow$Q, method=\"LH\") # get_BFM(bf)"},{"path":"https://louis-heraut.github.io/CARD/reference/get_MKH.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Mann-Kendall Test Decision ‚Äî get_MKH","title":"Get Mann-Kendall Test Decision ‚Äî get_MKH","text":"Extracts hypothesis test result (H) Generalized Mann-Kendall trend test, indicating whether significant trend exists.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/get_MKH.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Mann-Kendall Test Decision ‚Äî get_MKH","text":"","code":"get_MKH(X, level = 0.1, time_dependency_option = \"AR1\")"},{"path":"https://louis-heraut.github.io/CARD/reference/get_MKH.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Mann-Kendall Test Decision ‚Äî get_MKH","text":"X Numeric vector values test trend level numeric (0,1), level test. time_dependency_option string, option handling temporal dependence. Available : 'INDE', assume independence (.e. standard MK test) 'AR1', assumes AR1 short-term dependence structure (.e. Hamed Rao's version MK test) 'LTP', assume long-term persistence (.e. Hamed's version MK test)","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/get_MKH.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Mann-Kendall Test Decision ‚Äî get_MKH","text":"Logical value indicating test result: TRUE significant trend exists (reject null hypothesis) FALSE significant trend (fail reject null hypothesis)","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/get_MKH.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get Mann-Kendall Test Decision ‚Äî get_MKH","text":"H statistic indicates: TRUE (significant trend) p-value ‚â§ alpha FALSE (significant trend) p-value > alpha","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/get_MKH.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Mann-Kendall Test Decision ‚Äî get_MKH","text":"","code":"data(precipitation) #> Warning: data set ‚Äòprecipitation‚Äô not found # Check for significant trend in precipitation trend_exists <- get_MKH(precipitation$P) #> Error: object 'precipitation' not found"},{"path":"https://louis-heraut.github.io/CARD/reference/get_MKalpha.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Sen-Theil Slope Estimate ‚Äî get_MKalpha","title":"Get Sen-Theil Slope Estimate ‚Äî get_MKalpha","text":"Calculates Sen-Theil estimator (Œ±) trend magnitude Generalized Mann-Kendall test, representing median slope pairs points.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/get_MKalpha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Sen-Theil Slope Estimate ‚Äî get_MKalpha","text":"","code":"get_MKalpha(X, level = 0.1, time_dependency_option = \"AR1\")"},{"path":"https://louis-heraut.github.io/CARD/reference/get_MKalpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Sen-Theil Slope Estimate ‚Äî get_MKalpha","text":"X Numeric vector values analyze level numeric (0,1), level test. time_dependency_option string, option handling temporal dependence. Available : 'INDE', assume independence (.e. standard MK test) 'AR1', assumes AR1 short-term dependence structure (.e. Hamed Rao's version MK test) 'LTP', assume long-term persistence (.e. Hamed's version MK test)","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/get_MKalpha.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Sen-Theil Slope Estimate ‚Äî get_MKalpha","text":"Numeric value representing Sen-Theil slope estimate (Œ±) units X/time. Positive value indicates increasing trend Negative value indicates decreasing trend Zero indicates trend","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/get_MKalpha.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get Sen-Theil Slope Estimate ‚Äî get_MKalpha","text":"Sen-Theil estimator: Non-parametric median pairwise slopes: \\(\\alpha = median\\left(\\frac{X_j - X_i}{j-}\\right)\\) < j Robust outliers missing values Measures trend magnitude original units/time","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/get_MKalpha.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Sen-Theil Slope Estimate ‚Äî get_MKalpha","text":"","code":"data(streamflow) #> Warning: data set ‚Äòstreamflow‚Äô not found # Get trend slope in m¬≥/s per time unit trend_slope <- get_MKalpha(streamflow$Q) #> Error: object 'streamflow' not found print(paste(\"Trend slope:\", round(trend_slope, 4), \"m¬≥/s per time unit\")) #> Error: object 'trend_slope' not found"},{"path":"https://louis-heraut.github.io/CARD/reference/get_MKp.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Mann-Kendall P-Value ‚Äî get_MKp","title":"Get Mann-Kendall P-Value ‚Äî get_MKp","text":"Extracts p-value Generalized Mann-Kendall trend test.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/get_MKp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Mann-Kendall P-Value ‚Äî get_MKp","text":"","code":"get_MKp(X, level = 0.1, time_dependency_option = \"AR1\")"},{"path":"https://louis-heraut.github.io/CARD/reference/get_MKp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Mann-Kendall P-Value ‚Äî get_MKp","text":"X Numeric vector values test trend level numeric (0,1), level test. time_dependency_option string, option handling temporal dependence. Available : 'INDE', assume independence (.e. standard MK test) 'AR1', assumes AR1 short-term dependence structure (.e. Hamed Rao's version MK test) 'LTP', assume long-term persistence (.e. Hamed's version MK test)","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/get_MKp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Mann-Kendall P-Value ‚Äî get_MKp","text":"Numeric p-value 0 1 indicating probability observing trend chance true trend exists.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/get_MKp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get Mann-Kendall P-Value ‚Äî get_MKp","text":"Interpretation guidelines: p ‚â§ 0.01: strong evidence null hypothesis 0.01 < p ‚â§ 0.05: Strong evidence 0.05 < p ‚â§ 0.1: Weak evidence p > 0.1: Little evidence","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/get_MKp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Mann-Kendall P-Value ‚Äî get_MKp","text":"","code":"data(temperature) #> Warning: data set ‚Äòtemperature‚Äô not found # Get p-value for temperature trend pval <- get_MKp(temperature$T) #> Error: object 'temperature' not found print(paste(\"Trend significance:\", ifelse(pval < 0.05, \"Significant\", \"Not significant\"))) #> Error: object 'pval' not found"},{"path":"https://louis-heraut.github.io/CARD/reference/get_Xn.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized Return Value Calculator ‚Äî get_Xn","title":"Generalized Return Value Calculator ‚Äî get_Xn","text":"Computes return discharge value given time series return period, based specified hydrological regime (low high waters).","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/get_Xn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized Return Value Calculator ‚Äî get_Xn","text":"","code":"get_Xn(X, returnPeriod, waterType = \"low\", Date = NULL, period = NULL)"},{"path":"https://louis-heraut.github.io/CARD/reference/get_Xn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized Return Value Calculator ‚Äî get_Xn","text":"X Numeric vector flow values. returnPeriod Numeric value return period. waterType Character string, either 'low' log-normal estimation 'high' Gumbel-based estimation. Date Optional vector dates corresponding flow values. period Optional length-2 vector specifying start end period consider (must match class Date).","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/get_Xn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized Return Value Calculator ‚Äî get_Xn","text":"Numeric value estimated discharge given return period.","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/get_deltaX.html","id":null,"dir":"Reference","previous_headings":"","what":"get_deltaX ‚Äî get_deltaX","title":"get_deltaX ‚Äî get_deltaX","text":"description","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/get_deltaX.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"get_deltaX ‚Äî get_deltaX","text":"","code":"get_deltaX(   X,   Date,   past,   futur,   to_normalise,   returnPeriod = NULL,   waterType = \"low\",   Q_for_BFI = NULL )"},{"path":"https://louis-heraut.github.io/CARD/reference/get_deltaX.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"get_deltaX ‚Äî get_deltaX","text":"Q discharge","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/hsaCumsum.html","id":null,"dir":"Reference","previous_headings":"","what":"Enhanced Cumulative Sum Calculation ‚Äî hsaCumsum","title":"Enhanced Cumulative Sum Calculation ‚Äî hsaCumsum","text":"Computes cumulative sums options handling missing values (NA), including linear interpolation existing values.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/hsaCumsum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Enhanced Cumulative Sum Calculation ‚Äî hsaCumsum","text":"","code":"hsaCumsum(x, na.action = \"interpolate\")"},{"path":"https://louis-heraut.github.io/CARD/reference/hsaCumsum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Enhanced Cumulative Sum Calculation ‚Äî hsaCumsum","text":"x Numeric vector compute cumulative sums na.action Character numeric specifying NA handling: \"interpolate\": Linearly interpolates missing values (default) numeric value: Replaces NAs specified value value: Uses base cumsum() NAs propagating","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/hsaCumsum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Enhanced Cumulative Sum Calculation ‚Äî hsaCumsum","text":"Numeric vector cumulative sums length x: NAs start/end remain warning Interpolated values internal NAs na.action=\"interpolate\"","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/hsaCumsum.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Enhanced Cumulative Sum Calculation ‚Äî hsaCumsum","text":"na.action=\"interpolate\": Uses linear interpolation via stats::approx() Leading/trailing NAs set 0 warning Returns NA positions input NA","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/hsaCumsum.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Enhanced Cumulative Sum Calculation ‚Äî hsaCumsum","text":"","code":"x <- c(1, 2, NA, 4, 5, NA, 7)  # With interpolation hsaCumsum(x)  #> [1]  1  3  6 10 15 21 28  # With NA replacement hsaCumsum(x, na.action=0) #> [1]  1  3  3  7 12 12 19"},{"path":"https://louis-heraut.github.io/CARD/reference/inflect.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect Inflection Points in a Time Series ‚Äî inflect","title":"Detect Inflection Points in a Time Series ‚Äî inflect","text":"Identifies local minima maxima numeric vector using sliding window given threshold. Used detect changes trend smoothed hydrological data.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/inflect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect Inflection Points in a Time Series ‚Äî inflect","text":"","code":"inflect(x, threshold = 1)"},{"path":"https://louis-heraut.github.io/CARD/reference/inflect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect Inflection Points in a Time Series ‚Äî inflect","text":"x Numeric vector (e.g., smoothed discharge time series). threshold Integer. Number neighbors side consider identifying local extremum.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/inflect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect Inflection Points in a Time Series ‚Äî inflect","text":"list two integer vectors: minima (indices local minima) maxima (indices local maxima).","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/maxNA.html","id":null,"dir":"Reference","previous_headings":"","what":"maxNA ‚Äî maxNA","title":"maxNA ‚Äî maxNA","text":"description","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/maxNA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"maxNA ‚Äî maxNA","text":"","code":"maxNA(X, div = 1, na.rm = TRUE)"},{"path":"https://louis-heraut.github.io/CARD/reference/maxNA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"maxNA ‚Äî maxNA","text":"Q discharge","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/minNA.html","id":null,"dir":"Reference","previous_headings":"","what":"minNA ‚Äî minNA","title":"minNA ‚Äî minNA","text":"description","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/minNA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"minNA ‚Äî minNA","text":"","code":"minNA(X, div = 1, na.rm = TRUE)"},{"path":"https://louis-heraut.github.io/CARD/reference/minNA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"minNA ‚Äî minNA","text":"Q discharge","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/minus.html","id":null,"dir":"Reference","previous_headings":"","what":"minus ‚Äî minus","title":"minus ‚Äî minus","text":"description","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/minus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"minus ‚Äî minus","text":"","code":"minus(a, b, first = FALSE)"},{"path":"https://louis-heraut.github.io/CARD/reference/minus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"minus ‚Äî minus","text":"Q discharge","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/rollmean_center.html","id":null,"dir":"Reference","previous_headings":"","what":"rollmean_center ‚Äî rollmean_center","title":"rollmean_center ‚Äî rollmean_center","text":"description","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/rollmean_center.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"rollmean_center ‚Äî rollmean_center","text":"","code":"rollmean_center(X, k, isCyclical = FALSE)"},{"path":"https://louis-heraut.github.io/CARD/reference/rollmean_center.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"rollmean_center ‚Äî rollmean_center","text":"Q discharge","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/rollsum_center.html","id":null,"dir":"Reference","previous_headings":"","what":"rollsum_center ‚Äî rollsum_center","title":"rollsum_center ‚Äî rollsum_center","text":"description","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/rollsum_center.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"rollsum_center ‚Äî rollsum_center","text":"","code":"rollsum_center(X, k, isCyclical = FALSE)"},{"path":"https://louis-heraut.github.io/CARD/reference/rollsum_center.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"rollsum_center ‚Äî rollsum_center","text":"Q discharge","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/rq_slopes.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute R-Q Seasonal Slopes ‚Äî rq_slopes","title":"Compute R-Q Seasonal Slopes ‚Äî rq_slopes","text":"Analyzes seasonal response changes using cumulative precipitation-runoff (R-Q) differences, identifying breakpoints dry wet periods.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/rq_slopes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute R-Q Seasonal Slopes ‚Äî rq_slopes","text":"","code":"rq_slopes(   Q,   R,   hdays,   start = 15,   end = 183,   bp = mean(c(start, end)),   intercept = TRUE )"},{"path":"https://louis-heraut.github.io/CARD/reference/rq_slopes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute R-Q Seasonal Slopes ‚Äî rq_slopes","text":"Q Numeric vector streamflow values L¬≥/T R Numeric vector precipitation values L/T hdays Numeric vector hydrological day indices (1-365/366) start Integer first day analyze (default: 15) end Integer last day analyze (default: 183) bp Initial guess breakpoint day (default: midpoint start/end) intercept Logical indicating whether estimate intercepts (TRUE) fix 0 (FALSE)","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/rq_slopes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute R-Q Seasonal Slopes ‚Äî rq_slopes","text":"Named numeric vector containing: bp: Breakpoint day bp_strength: Magnitude slope change slp_dry: Dry period slope b_dry: Dry period intercept slp_wet: Wet period slope b_wet: Wet period intercept","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/sourceProcess.html","id":null,"dir":"Reference","previous_headings":"","what":"sourceProcess ‚Äî sourceProcess","title":"sourceProcess ‚Äî sourceProcess","text":"Allows read CARD formatism convert Process variable explain step necessary extraction process_extraction().","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/sourceProcess.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"sourceProcess ‚Äî sourceProcess","text":"","code":"sourceProcess(path, default = NULL)"},{"path":"https://louis-heraut.github.io/CARD/reference/sourceProcess.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"sourceProcess ‚Äî sourceProcess","text":"path character string path CARD file. default default process loaded Process_default = sourceProcess(file.path(CARD_path, \"__default__.R\")) load default parameters every extraction process. Default NULL.","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/sourceProcess.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"sourceProcess ‚Äî sourceProcess","text":"Process variable list general parameters, sub list extraction process parameters.","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/sourceProcess.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"sourceProcess ‚Äî sourceProcess","text":"","code":"if (FALSE) { # \\dontrun{ Process_default = sourceProcess(path=\"path/to/CARD/__default__.R\") Process = sourceProcess(path=\"path/to/CARD/script.R\",                         default=Process_default) } # }"},{"path":"https://louis-heraut.github.io/CARD/reference/sumNA.html","id":null,"dir":"Reference","previous_headings":"","what":"sumNA ‚Äî sumNA","title":"sumNA ‚Äî sumNA","text":"description","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/sumNA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"sumNA ‚Äî sumNA","text":"","code":"sumNA(X, div = 1, na.rm = TRUE)"},{"path":"https://louis-heraut.github.io/CARD/reference/sumNA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"sumNA ‚Äî sumNA","text":"Q discharge","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/which.maxNA.html","id":null,"dir":"Reference","previous_headings":"","what":"which.maxNA ‚Äî which.maxNA","title":"which.maxNA ‚Äî which.maxNA","text":"description","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/which.maxNA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"which.maxNA ‚Äî which.maxNA","text":"","code":"which.maxNA(X)"},{"path":"https://louis-heraut.github.io/CARD/reference/which.maxNA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"which.maxNA ‚Äî which.maxNA","text":"Q discharge","code":""},{"path":[]},{"path":"https://louis-heraut.github.io/CARD/reference/which.minNA.html","id":null,"dir":"Reference","previous_headings":"","what":"which.minNA ‚Äî which.minNA","title":"which.minNA ‚Äî which.minNA","text":"description","code":""},{"path":"https://louis-heraut.github.io/CARD/reference/which.minNA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"which.minNA ‚Äî which.minNA","text":"","code":"which.minNA(X)"},{"path":"https://louis-heraut.github.io/CARD/reference/which.minNA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"which.minNA ‚Äî which.minNA","text":"Q discharge","code":""},{"path":[]}]
